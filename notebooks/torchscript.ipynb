{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3acc7aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "################################################################################\n",
      "### WARNING, path does not exist: KALDI_ROOT=/mnt/matylda5/iveselyk/Tools/kaldi-trunk\n",
      "###          (please add 'export KALDI_ROOT=<your_path>' in your $HOME/.profile)\n",
      "###          (or run as: KALDI_ROOT=<your_path> python <your_script>.py)\n",
      "################################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import soundfile as sf\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd7ef9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.jit.load('/home/harveen/vakyansh-nemo-experimentation/checkpoints/torchscript/hindi_medium_hi.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "688c9481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    input: Tensor,\n",
      "    length: Tensor) -> Tensor:\n",
      "  x = torch.transpose(input, 1, 2)\n",
      "  _0 = torch.add(torch.to(length, 6), CONSTANTS.c0)\n",
      "  lengths = torch.add(torch.div(_0, CONSTANTS.c1), CONSTANTS.c2)\n",
      "  lengths0 = torch.floor(lengths)\n",
      "  lengths1 = torch.to(lengths0, 6)\n",
      "  _1 = torch.div(torch.add(lengths1, CONSTANTS.c0), CONSTANTS.c1)\n",
      "  lengths2 = torch.add(_1, CONSTANTS.c2)\n",
      "  lengths3 = torch.floor(lengths2)\n",
      "  seq_lens = torch.to(lengths3, 3)\n",
      "  input0 = torch.unsqueeze(x, 1)\n",
      "  _2 = torch.cudnn_convolution_relu(torch.to(input0, 5), CONSTANTS.c3, CONSTANTS.c4, [2, 2], [1, 1], [1, 1], 1)\n",
      "  _3 = torch.cudnn_convolution_relu(_2, CONSTANTS.c5, CONSTANTS.c6, [2, 2], [1, 1], [1, 1], 1)\n",
      "  _4 = torch.size(_3, 0)\n",
      "  _5 = torch.size(_3, 2)\n",
      "  input1 = torch.reshape(torch.transpose(_3, 1, 2), [_4, _5, -1])\n",
      "  _6 = torch.add(torch.matmul(input1, CONSTANTS.c7), CONSTANTS.c8)\n",
      "  x0 = torch.mul(_6, CONSTANTS.c9)\n",
      "  _7 = ops.prim.NumToTensor(torch.size(x0, 1))\n",
      "  start_pos = torch.sub(CONSTANTS.c10, _7)\n",
      "  _8 = int(start_pos)\n",
      "  end_pos = torch.sub(torch.add(CONSTANTS.c10, _7), CONSTANTS.c11)\n",
      "  pos_emb = torch.slice(CONSTANTS.c12, 1, _8, int(end_pos))\n",
      "  _9 = torch.size(x0, 1)\n",
      "  _10 = torch.expand(torch.slice(CONSTANTS.c13, 0, 0, _9), [torch.size(seq_lens, 0), -1])\n",
      "  pad_mask = torch.lt(_10, torch.unsqueeze(seq_lens, -1))\n",
      "  att_mask = torch.repeat(torch.unsqueeze(pad_mask, 1), [1, _9, 1])\n",
      "  att_mask0 = torch.logical_and(att_mask, torch.transpose(att_mask, 1, 2))\n",
      "  mask = torch.bitwise_not(att_mask0)\n",
      "  pad_mask0 = torch.bitwise_not(pad_mask)\n",
      "  input2 = torch.to(x0, 6)\n",
      "  _11 = torch.layer_norm(input2, [256], CONSTANTS.c14, CONSTANTS.c15)\n",
      "  input3 = torch.to(_11, 5)\n",
      "  _12 = torch.add(torch.matmul(input3, CONSTANTS.c16), CONSTANTS.c17)\n",
      "  input4 = torch.silu(_12)\n",
      "  _13 = torch.add(torch.matmul(input4, CONSTANTS.c18), CONSTANTS.c19)\n",
      "  x1 = torch.add(x0, torch.mul(_13, CONSTANTS.c20))\n",
      "  input5 = torch.to(x1, 6)\n",
      "  _14 = torch.layer_norm(input5, [256], CONSTANTS.c21, CONSTANTS.c22)\n",
      "  query = torch.to(_14, 5)\n",
      "  _15 = torch.size(query, 0)\n",
      "  _16 = torch.add(torch.matmul(query, CONSTANTS.c23), CONSTANTS.c24)\n",
      "  _17 = torch.slice(_16, -1, 512, 768)\n",
      "  _18 = torch.slice(_16, -1, 256, 512)\n",
      "  _19 = torch.slice(_16, -1, 0, 256)\n",
      "  _20 = [_15, -1, 4, 64]\n",
      "  q = torch.view(_19, _20)\n",
      "  k = torch.view(_18, _20)\n",
      "  v = torch.view(_17, _20)\n",
      "  q0 = torch.transpose(q, 1, 2)\n",
      "  k0 = torch.transpose(k, 1, 2)\n",
      "  value = torch.transpose(v, 1, 2)\n",
      "  q1 = torch.transpose(q0, 1, 2)\n",
      "  _21 = torch.size(pos_emb, 0)\n",
      "  _22 = torch.to(pos_emb, 5)\n",
      "  _23 = torch.matmul(_22, CONSTANTS.c25)\n",
      "  _24 = [_21, -1, 4, 64]\n",
      "  p = torch.view(_23, _24)\n",
      "  p0 = torch.transpose(p, 1, 2)\n",
      "  q_with_bias_u = torch.transpose(torch.add(q1, CONSTANTS.c26), 1, 2)\n",
      "  q_with_bias_v = torch.transpose(torch.add(q1, CONSTANTS.c27), 1, 2)\n",
      "  _25 = torch.transpose(k0, -2, -1)\n",
      "  matrix_ac = torch.matmul(torch.to(q_with_bias_u, 5), _25)\n",
      "  _26 = torch.transpose(p0, -2, -1)\n",
      "  x2 = torch.matmul(torch.to(q_with_bias_v, 5), _26)\n",
      "  _27 = torch.size(x2, 0)\n",
      "  _28 = torch.size(x2, 1)\n",
      "  _29 = torch.size(x2, 2)\n",
      "  _30 = torch.size(x2, 3)\n",
      "  x3 = torch.constant_pad_nd(x2, [1, 0], 0.)\n",
      "  x4 = torch.view(x3, [_27, _28, -1, _29])\n",
      "  _31 = torch.slice(x4, 0, 0, 9223372036854775807)\n",
      "  _32 = torch.slice(_31, 1, 0, 9223372036854775807)\n",
      "  _33 = torch.slice(_32, 2, 1, 9223372036854775807)\n",
      "  matrix_bd = torch.view(_33, [_27, _28, _29, _30])\n",
      "  _34 = torch.size(matrix_ac, -1)\n",
      "  _35 = torch.slice(matrix_bd, 0, 0, 9223372036854775807)\n",
      "  _36 = torch.slice(_35, 1, 0, 9223372036854775807)\n",
      "  _37 = torch.slice(_36, 2, 0, 9223372036854775807)\n",
      "  matrix_bd0 = torch.slice(_37, 3, 0, _34)\n",
      "  scores = torch.div(torch.add(matrix_ac, matrix_bd0), CONSTANTS.c28)\n",
      "  _38 = torch.size(value, 0)\n",
      "  mask0 = torch.unsqueeze(mask, 1)\n",
      "  scores0 = torch.masked_fill(scores, mask0, -10000.)\n",
      "  input6 = torch.masked_fill(torch.softmax(scores0, -1, 6), mask0, 0.)\n",
      "  x5 = torch.matmul(torch.to(input6, 5), value)\n",
      "  input7 = torch.reshape(torch.transpose(x5, 1, 2), [_38, -1, 256])\n",
      "  _39 = torch.add(torch.matmul(input7, CONSTANTS.c29), CONSTANTS.c30)\n",
      "  x6 = torch.add(x1, _39)\n",
      "  input8 = torch.to(x6, 6)\n",
      "  _40 = torch.layer_norm(input8, [256], CONSTANTS.c31, CONSTANTS.c32)\n",
      "  x7 = torch.to(_40, 5)\n",
      "  input9 = torch.transpose(x7, 1, 2)\n",
      "  _41 = torch.conv1d(input9, CONSTANTS.c33, CONSTANTS.c34)\n",
      "  x8 = torch.glu(_41, 1)\n",
      "  _42 = torch.to(x8, 6)\n",
      "  _43 = torch.unsqueeze(pad_mask0, 1)\n",
      "  input10 = torch.masked_fill(_42, _43, 0.)\n",
      "  _44 = torch.conv1d(torch.to(input10, 5), CONSTANTS.c35, CONSTANTS.c36, [1], [15], [1], 256)\n",
      "  input11 = torch.to(_44, 6)\n",
      "  _45 = torch.batch_norm(input11, CONSTANTS.c37, CONSTANTS.c38, CONSTANTS.c39, CONSTANTS.c40, False, 0.10000000000000001, 1.0000000000000001e-05, True)\n",
      "  input12 = torch.to(_45, 5)\n",
      "  input13 = torch.silu(input12)\n",
      "  _46 = torch.conv1d(input13, CONSTANTS.c41, CONSTANTS.c42)\n",
      "  input14 = torch.transpose(_46, 1, 2)\n",
      "  x9 = torch.add(x6, input14)\n",
      "  input15 = torch.to(x9, 6)\n",
      "  _47 = torch.layer_norm(input15, [256], CONSTANTS.c43, CONSTANTS.c44)\n",
      "  input16 = torch.to(_47, 5)\n",
      "  _48 = torch.add(torch.matmul(input16, CONSTANTS.c45), CONSTANTS.c46)\n",
      "  input17 = torch.silu(_48)\n",
      "  _49 = torch.add(torch.matmul(input17, CONSTANTS.c47), CONSTANTS.c48)\n",
      "  x10 = torch.add(x9, torch.mul(_49, CONSTANTS.c20))\n",
      "  input18 = torch.to(x10, 6)\n",
      "  _50 = torch.layer_norm(input18, [256], CONSTANTS.c49, CONSTANTS.c50)\n",
      "  x11 = torch.to(_50, 5)\n",
      "  input19 = torch.to(x11, 6)\n",
      "  _51 = torch.layer_norm(input19, [256], CONSTANTS.c51, CONSTANTS.c52)\n",
      "  input20 = torch.to(_51, 5)\n",
      "  _52 = torch.add(torch.matmul(input20, CONSTANTS.c53), CONSTANTS.c54)\n",
      "  input21 = torch.silu(_52)\n",
      "  _53 = torch.add(torch.matmul(input21, CONSTANTS.c55), CONSTANTS.c56)\n",
      "  x12 = torch.add(x11, torch.mul(_53, CONSTANTS.c20))\n",
      "  input22 = torch.to(x12, 6)\n",
      "  _54 = torch.layer_norm(input22, [256], CONSTANTS.c57, CONSTANTS.c58)\n",
      "  query0 = torch.to(_54, 5)\n",
      "  _55 = torch.size(query0, 0)\n",
      "  _56 = torch.add(torch.matmul(query0, CONSTANTS.c59), CONSTANTS.c60)\n",
      "  _57 = torch.slice(_56, -1, 512, 768)\n",
      "  _58 = torch.slice(_56, -1, 256, 512)\n",
      "  _59 = torch.slice(_56, -1, 0, 256)\n",
      "  _60 = [_55, -1, 4, 64]\n",
      "  q2 = torch.view(_59, _60)\n",
      "  k1 = torch.view(_58, _60)\n",
      "  v0 = torch.view(_57, _60)\n",
      "  q3 = torch.transpose(q2, 1, 2)\n",
      "  k2 = torch.transpose(k1, 1, 2)\n",
      "  value0 = torch.transpose(v0, 1, 2)\n",
      "  q4 = torch.transpose(q3, 1, 2)\n",
      "  p1 = torch.view(torch.matmul(_22, CONSTANTS.c61), _24)\n",
      "  p2 = torch.transpose(p1, 1, 2)\n",
      "  q_with_bias_u0 = torch.transpose(torch.add(q4, CONSTANTS.c62), 1, 2)\n",
      "  q_with_bias_v0 = torch.transpose(torch.add(q4, CONSTANTS.c63), 1, 2)\n",
      "  _61 = torch.transpose(k2, -2, -1)\n",
      "  matrix_ac0 = torch.matmul(torch.to(q_with_bias_u0, 5), _61)\n",
      "  _62 = torch.transpose(p2, -2, -1)\n",
      "  x13 = torch.matmul(torch.to(q_with_bias_v0, 5), _62)\n",
      "  _63 = torch.size(x13, 0)\n",
      "  _64 = torch.size(x13, 1)\n",
      "  _65 = torch.size(x13, 2)\n",
      "  _66 = torch.size(x13, 3)\n",
      "  x14 = torch.constant_pad_nd(x13, [1, 0], 0.)\n",
      "  x15 = torch.view(x14, [_63, _64, -1, _65])\n",
      "  _67 = torch.slice(x15, 0, 0, 9223372036854775807)\n",
      "  _68 = torch.slice(_67, 1, 0, 9223372036854775807)\n",
      "  _69 = torch.slice(_68, 2, 1, 9223372036854775807)\n",
      "  matrix_bd1 = torch.view(_69, [_63, _64, _65, _66])\n",
      "  _70 = torch.size(matrix_ac0, -1)\n",
      "  _71 = torch.slice(matrix_bd1, 0, 0, 9223372036854775807)\n",
      "  _72 = torch.slice(_71, 1, 0, 9223372036854775807)\n",
      "  _73 = torch.slice(_72, 2, 0, 9223372036854775807)\n",
      "  matrix_bd2 = torch.slice(_73, 3, 0, _70)\n",
      "  scores1 = torch.div(torch.add(matrix_ac0, matrix_bd2), CONSTANTS.c28)\n",
      "  _74 = torch.size(value0, 0)\n",
      "  scores2 = torch.masked_fill(scores1, mask0, -10000.)\n",
      "  input23 = torch.masked_fill(torch.softmax(scores2, -1, 6), mask0, 0.)\n",
      "  x16 = torch.matmul(torch.to(input23, 5), value0)\n",
      "  input24 = torch.reshape(torch.transpose(x16, 1, 2), [_74, -1, 256])\n",
      "  _75 = torch.add(torch.matmul(input24, CONSTANTS.c64), CONSTANTS.c65)\n",
      "  x17 = torch.add(x12, _75)\n",
      "  input25 = torch.to(x17, 6)\n",
      "  _76 = torch.layer_norm(input25, [256], CONSTANTS.c66, CONSTANTS.c67)\n",
      "  x18 = torch.to(_76, 5)\n",
      "  input26 = torch.transpose(x18, 1, 2)\n",
      "  _77 = torch.conv1d(input26, CONSTANTS.c68, CONSTANTS.c69)\n",
      "  x19 = torch.glu(_77, 1)\n",
      "  input27 = torch.masked_fill(torch.to(x19, 6), _43, 0.)\n",
      "  _78 = torch.conv1d(torch.to(input27, 5), CONSTANTS.c70, CONSTANTS.c71, [1], [15], [1], 256)\n",
      "  input28 = torch.to(_78, 6)\n",
      "  _79 = torch.batch_norm(input28, CONSTANTS.c72, CONSTANTS.c73, CONSTANTS.c74, CONSTANTS.c75, False, 0.10000000000000001, 1.0000000000000001e-05, True)\n",
      "  input29 = torch.to(_79, 5)\n",
      "  input30 = torch.silu(input29)\n",
      "  _80 = torch.conv1d(input30, CONSTANTS.c76, CONSTANTS.c77)\n",
      "  input31 = torch.transpose(_80, 1, 2)\n",
      "  x20 = torch.add(x17, input31)\n",
      "  input32 = torch.to(x20, 6)\n",
      "  _81 = torch.layer_norm(input32, [256], CONSTANTS.c78, CONSTANTS.c79)\n",
      "  input33 = torch.to(_81, 5)\n",
      "  _82 = torch.add(torch.matmul(input33, CONSTANTS.c80), CONSTANTS.c81)\n",
      "  input34 = torch.silu(_82)\n",
      "  _83 = torch.add(torch.matmul(input34, CONSTANTS.c82), CONSTANTS.c83)\n",
      "  x21 = torch.add(x20, torch.mul(_83, CONSTANTS.c20))\n",
      "  input35 = torch.to(x21, 6)\n",
      "  _84 = torch.layer_norm(input35, [256], CONSTANTS.c84, CONSTANTS.c85)\n",
      "  x22 = torch.to(_84, 5)\n",
      "  input36 = torch.to(x22, 6)\n",
      "  _85 = torch.layer_norm(input36, [256], CONSTANTS.c86, CONSTANTS.c87)\n",
      "  input37 = torch.to(_85, 5)\n",
      "  _86 = torch.add(torch.matmul(input37, CONSTANTS.c88), CONSTANTS.c89)\n",
      "  input38 = torch.silu(_86)\n",
      "  _87 = torch.add(torch.matmul(input38, CONSTANTS.c90), CONSTANTS.c91)\n",
      "  x23 = torch.add(x22, torch.mul(_87, CONSTANTS.c20))\n",
      "  input39 = torch.to(x23, 6)\n",
      "  _88 = torch.layer_norm(input39, [256], CONSTANTS.c92, CONSTANTS.c93)\n",
      "  query1 = torch.to(_88, 5)\n",
      "  _89 = torch.size(query1, 0)\n",
      "  _90 = torch.add(torch.matmul(query1, CONSTANTS.c94), CONSTANTS.c95)\n",
      "  _91 = torch.slice(_90, -1, 512, 768)\n",
      "  _92 = torch.slice(_90, -1, 256, 512)\n",
      "  _93 = torch.slice(_90, -1, 0, 256)\n",
      "  _94 = [_89, -1, 4, 64]\n",
      "  q5 = torch.view(_93, _94)\n",
      "  k3 = torch.view(_92, _94)\n",
      "  v1 = torch.view(_91, _94)\n",
      "  q6 = torch.transpose(q5, 1, 2)\n",
      "  k4 = torch.transpose(k3, 1, 2)\n",
      "  value1 = torch.transpose(v1, 1, 2)\n",
      "  q7 = torch.transpose(q6, 1, 2)\n",
      "  p3 = torch.view(torch.matmul(_22, CONSTANTS.c96), _24)\n",
      "  p4 = torch.transpose(p3, 1, 2)\n",
      "  q_with_bias_u1 = torch.transpose(torch.add(q7, CONSTANTS.c97), 1, 2)\n",
      "  q_with_bias_v1 = torch.transpose(torch.add(q7, CONSTANTS.c98), 1, 2)\n",
      "  _95 = torch.transpose(k4, -2, -1)\n",
      "  matrix_ac1 = torch.matmul(torch.to(q_with_bias_u1, 5), _95)\n",
      "  _96 = torch.transpose(p4, -2, -1)\n",
      "  x24 = torch.matmul(torch.to(q_with_bias_v1, 5), _96)\n",
      "  _97 = torch.size(x24, 0)\n",
      "  _98 = torch.size(x24, 1)\n",
      "  _99 = torch.size(x24, 2)\n",
      "  _100 = torch.size(x24, 3)\n",
      "  x25 = torch.constant_pad_nd(x24, [1, 0], 0.)\n",
      "  x26 = torch.view(x25, [_97, _98, -1, _99])\n",
      "  _101 = torch.slice(x26, 0, 0, 9223372036854775807)\n",
      "  _102 = torch.slice(_101, 1, 0, 9223372036854775807)\n",
      "  _103 = torch.slice(_102, 2, 1, 9223372036854775807)\n",
      "  matrix_bd3 = torch.view(_103, [_97, _98, _99, _100])\n",
      "  _104 = torch.size(matrix_ac1, -1)\n",
      "  _105 = torch.slice(matrix_bd3, 0, 0, 9223372036854775807)\n",
      "  _106 = torch.slice(_105, 1, 0, 9223372036854775807)\n",
      "  _107 = torch.slice(_106, 2, 0, 9223372036854775807)\n",
      "  matrix_bd4 = torch.slice(_107, 3, 0, _104)\n",
      "  scores3 = torch.div(torch.add(matrix_ac1, matrix_bd4), CONSTANTS.c28)\n",
      "  _108 = torch.size(value1, 0)\n",
      "  scores4 = torch.masked_fill(scores3, mask0, -10000.)\n",
      "  input40 = torch.masked_fill(torch.softmax(scores4, -1, 6), mask0, 0.)\n",
      "  x27 = torch.matmul(torch.to(input40, 5), value1)\n",
      "  input41 = torch.reshape(torch.transpose(x27, 1, 2), [_108, -1, 256])\n",
      "  _109 = torch.add(torch.matmul(input41, CONSTANTS.c99), CONSTANTS.c100)\n",
      "  x28 = torch.add(x23, _109)\n",
      "  input42 = torch.to(x28, 6)\n",
      "  _110 = torch.layer_norm(input42, [256], CONSTANTS.c101, CONSTANTS.c102)\n",
      "  x29 = torch.to(_110, 5)\n",
      "  input43 = torch.transpose(x29, 1, 2)\n",
      "  _111 = torch.conv1d(input43, CONSTANTS.c103, CONSTANTS.c104)\n",
      "  x30 = torch.glu(_111, 1)\n",
      "  input44 = torch.masked_fill(torch.to(x30, 6), _43, 0.)\n",
      "  _112 = torch.conv1d(torch.to(input44, 5), CONSTANTS.c105, CONSTANTS.c106, [1], [15], [1], 256)\n",
      "  input45 = torch.to(_112, 6)\n",
      "  _113 = torch.batch_norm(input45, CONSTANTS.c107, CONSTANTS.c108, CONSTANTS.c109, CONSTANTS.c110, False, 0.10000000000000001, 1.0000000000000001e-05, True)\n",
      "  input46 = torch.to(_113, 5)\n",
      "  input47 = torch.silu(input46)\n",
      "  _114 = torch.conv1d(input47, CONSTANTS.c111, CONSTANTS.c112)\n",
      "  input48 = torch.transpose(_114, 1, 2)\n",
      "  x31 = torch.add(x28, input48)\n",
      "  input49 = torch.to(x31, 6)\n",
      "  _115 = torch.layer_norm(input49, [256], CONSTANTS.c113, CONSTANTS.c114)\n",
      "  input50 = torch.to(_115, 5)\n",
      "  _116 = torch.add(torch.matmul(input50, CONSTANTS.c115), CONSTANTS.c116)\n",
      "  input51 = torch.silu(_116)\n",
      "  _117 = torch.add(torch.matmul(input51, CONSTANTS.c117), CONSTANTS.c118)\n",
      "  x32 = torch.add(x31, torch.mul(_117, CONSTANTS.c20))\n",
      "  input52 = torch.to(x32, 6)\n",
      "  _118 = torch.layer_norm(input52, [256], CONSTANTS.c119, CONSTANTS.c120)\n",
      "  x33 = torch.to(_118, 5)\n",
      "  input53 = torch.to(x33, 6)\n",
      "  _119 = torch.layer_norm(input53, [256], CONSTANTS.c121, CONSTANTS.c122)\n",
      "  input54 = torch.to(_119, 5)\n",
      "  _120 = torch.add(torch.matmul(input54, CONSTANTS.c123), CONSTANTS.c124)\n",
      "  input55 = torch.silu(_120)\n",
      "  _121 = torch.add(torch.matmul(input55, CONSTANTS.c125), CONSTANTS.c126)\n",
      "  x34 = torch.add(x33, torch.mul(_121, CONSTANTS.c20))\n",
      "  input56 = torch.to(x34, 6)\n",
      "  _122 = torch.layer_norm(input56, [256], CONSTANTS.c127, CONSTANTS.c128)\n",
      "  query2 = torch.to(_122, 5)\n",
      "  _123 = torch.size(query2, 0)\n",
      "  _124 = torch.add(torch.matmul(query2, CONSTANTS.c129), CONSTANTS.c130)\n",
      "  _125 = torch.slice(_124, -1, 512, 768)\n",
      "  _126 = torch.slice(_124, -1, 256, 512)\n",
      "  _127 = torch.slice(_124, -1, 0, 256)\n",
      "  _128 = [_123, -1, 4, 64]\n",
      "  q8 = torch.view(_127, _128)\n",
      "  k5 = torch.view(_126, _128)\n",
      "  v2 = torch.view(_125, _128)\n",
      "  q9 = torch.transpose(q8, 1, 2)\n",
      "  k6 = torch.transpose(k5, 1, 2)\n",
      "  value2 = torch.transpose(v2, 1, 2)\n",
      "  q10 = torch.transpose(q9, 1, 2)\n",
      "  p5 = torch.view(torch.matmul(_22, CONSTANTS.c131), _24)\n",
      "  p6 = torch.transpose(p5, 1, 2)\n",
      "  q_with_bias_u2 = torch.transpose(torch.add(q10, CONSTANTS.c132), 1, 2)\n",
      "  q_with_bias_v2 = torch.transpose(torch.add(q10, CONSTANTS.c133), 1, 2)\n",
      "  _129 = torch.transpose(k6, -2, -1)\n",
      "  matrix_ac2 = torch.matmul(torch.to(q_with_bias_u2, 5), _129)\n",
      "  _130 = torch.transpose(p6, -2, -1)\n",
      "  x35 = torch.matmul(torch.to(q_with_bias_v2, 5), _130)\n",
      "  _131 = torch.size(x35, 0)\n",
      "  _132 = torch.size(x35, 1)\n",
      "  _133 = torch.size(x35, 2)\n",
      "  _134 = torch.size(x35, 3)\n",
      "  x36 = torch.constant_pad_nd(x35, [1, 0], 0.)\n",
      "  x37 = torch.view(x36, [_131, _132, -1, _133])\n",
      "  _135 = torch.slice(x37, 0, 0, 9223372036854775807)\n",
      "  _136 = torch.slice(_135, 1, 0, 9223372036854775807)\n",
      "  _137 = torch.slice(_136, 2, 1, 9223372036854775807)\n",
      "  matrix_bd5 = torch.view(_137, [_131, _132, _133, _134])\n",
      "  _138 = torch.size(matrix_ac2, -1)\n",
      "  _139 = torch.slice(matrix_bd5, 0, 0, 9223372036854775807)\n",
      "  _140 = torch.slice(_139, 1, 0, 9223372036854775807)\n",
      "  _141 = torch.slice(_140, 2, 0, 9223372036854775807)\n",
      "  matrix_bd6 = torch.slice(_141, 3, 0, _138)\n",
      "  scores5 = torch.div(torch.add(matrix_ac2, matrix_bd6), CONSTANTS.c28)\n",
      "  _142 = torch.size(value2, 0)\n",
      "  scores6 = torch.masked_fill(scores5, mask0, -10000.)\n",
      "  input57 = torch.masked_fill(torch.softmax(scores6, -1, 6), mask0, 0.)\n",
      "  x38 = torch.matmul(torch.to(input57, 5), value2)\n",
      "  input58 = torch.reshape(torch.transpose(x38, 1, 2), [_142, -1, 256])\n",
      "  _143 = torch.add(torch.matmul(input58, CONSTANTS.c134), CONSTANTS.c135)\n",
      "  x39 = torch.add(x34, _143)\n",
      "  input59 = torch.to(x39, 6)\n",
      "  _144 = torch.layer_norm(input59, [256], CONSTANTS.c136, CONSTANTS.c137)\n",
      "  x40 = torch.to(_144, 5)\n",
      "  input60 = torch.transpose(x40, 1, 2)\n",
      "  _145 = torch.conv1d(input60, CONSTANTS.c138, CONSTANTS.c139)\n",
      "  x41 = torch.glu(_145, 1)\n",
      "  input61 = torch.masked_fill(torch.to(x41, 6), _43, 0.)\n",
      "  _146 = torch.conv1d(torch.to(input61, 5), CONSTANTS.c140, CONSTANTS.c141, [1], [15], [1], 256)\n",
      "  input62 = torch.to(_146, 6)\n",
      "  _147 = torch.batch_norm(input62, CONSTANTS.c142, CONSTANTS.c143, CONSTANTS.c144, CONSTANTS.c145, False, 0.10000000000000001, 1.0000000000000001e-05, True)\n",
      "  input63 = torch.to(_147, 5)\n",
      "  input64 = torch.silu(input63)\n",
      "  _148 = torch.conv1d(input64, CONSTANTS.c146, CONSTANTS.c147)\n",
      "  input65 = torch.transpose(_148, 1, 2)\n",
      "  x42 = torch.add(x39, input65)\n",
      "  input66 = torch.to(x42, 6)\n",
      "  _149 = torch.layer_norm(input66, [256], CONSTANTS.c148, CONSTANTS.c149)\n",
      "  input67 = torch.to(_149, 5)\n",
      "  _150 = torch.add(torch.matmul(input67, CONSTANTS.c150), CONSTANTS.c151)\n",
      "  input68 = torch.silu(_150)\n",
      "  _151 = torch.add(torch.matmul(input68, CONSTANTS.c152), CONSTANTS.c153)\n",
      "  x43 = torch.add(x42, torch.mul(_151, CONSTANTS.c20))\n",
      "  input69 = torch.to(x43, 6)\n",
      "  _152 = torch.layer_norm(input69, [256], CONSTANTS.c154, CONSTANTS.c155)\n",
      "  x44 = torch.to(_152, 5)\n",
      "  input70 = torch.to(x44, 6)\n",
      "  _153 = torch.layer_norm(input70, [256], CONSTANTS.c156, CONSTANTS.c157)\n",
      "  input71 = torch.to(_153, 5)\n",
      "  _154 = torch.add(torch.matmul(input71, CONSTANTS.c158), CONSTANTS.c159)\n",
      "  input72 = torch.silu(_154)\n",
      "  _155 = torch.add(torch.matmul(input72, CONSTANTS.c160), CONSTANTS.c161)\n",
      "  x45 = torch.add(x44, torch.mul(_155, CONSTANTS.c20))\n",
      "  input73 = torch.to(x45, 6)\n",
      "  _156 = torch.layer_norm(input73, [256], CONSTANTS.c162, CONSTANTS.c163)\n",
      "  query3 = torch.to(_156, 5)\n",
      "  _157 = torch.size(query3, 0)\n",
      "  _158 = torch.add(torch.matmul(query3, CONSTANTS.c164), CONSTANTS.c165)\n",
      "  _159 = torch.slice(_158, -1, 512, 768)\n",
      "  _160 = torch.slice(_158, -1, 256, 512)\n",
      "  _161 = torch.slice(_158, -1, 0, 256)\n",
      "  _162 = [_157, -1, 4, 64]\n",
      "  q11 = torch.view(_161, _162)\n",
      "  k7 = torch.view(_160, _162)\n",
      "  v3 = torch.view(_159, _162)\n",
      "  q12 = torch.transpose(q11, 1, 2)\n",
      "  k8 = torch.transpose(k7, 1, 2)\n",
      "  value3 = torch.transpose(v3, 1, 2)\n",
      "  q13 = torch.transpose(q12, 1, 2)\n",
      "  p7 = torch.view(torch.matmul(_22, CONSTANTS.c166), _24)\n",
      "  p8 = torch.transpose(p7, 1, 2)\n",
      "  q_with_bias_u3 = torch.transpose(torch.add(q13, CONSTANTS.c167), 1, 2)\n",
      "  q_with_bias_v3 = torch.transpose(torch.add(q13, CONSTANTS.c168), 1, 2)\n",
      "  _163 = torch.transpose(k8, -2, -1)\n",
      "  matrix_ac3 = torch.matmul(torch.to(q_with_bias_u3, 5), _163)\n",
      "  _164 = torch.transpose(p8, -2, -1)\n",
      "  x46 = torch.matmul(torch.to(q_with_bias_v3, 5), _164)\n",
      "  _165 = torch.size(x46, 0)\n",
      "  _166 = torch.size(x46, 1)\n",
      "  _167 = torch.size(x46, 2)\n",
      "  _168 = torch.size(x46, 3)\n",
      "  x47 = torch.constant_pad_nd(x46, [1, 0], 0.)\n",
      "  x48 = torch.view(x47, [_165, _166, -1, _167])\n",
      "  _169 = torch.slice(x48, 0, 0, 9223372036854775807)\n",
      "  _170 = torch.slice(_169, 1, 0, 9223372036854775807)\n",
      "  _171 = torch.slice(_170, 2, 1, 9223372036854775807)\n",
      "  matrix_bd7 = torch.view(_171, [_165, _166, _167, _168])\n",
      "  _172 = torch.size(matrix_ac3, -1)\n",
      "  _173 = torch.slice(matrix_bd7, 0, 0, 9223372036854775807)\n",
      "  _174 = torch.slice(_173, 1, 0, 9223372036854775807)\n",
      "  _175 = torch.slice(_174, 2, 0, 9223372036854775807)\n",
      "  matrix_bd8 = torch.slice(_175, 3, 0, _172)\n",
      "  scores7 = torch.div(torch.add(matrix_ac3, matrix_bd8), CONSTANTS.c28)\n",
      "  _176 = torch.size(value3, 0)\n",
      "  scores8 = torch.masked_fill(scores7, mask0, -10000.)\n",
      "  input74 = torch.masked_fill(torch.softmax(scores8, -1, 6), mask0, 0.)\n",
      "  x49 = torch.matmul(torch.to(input74, 5), value3)\n",
      "  input75 = torch.reshape(torch.transpose(x49, 1, 2), [_176, -1, 256])\n",
      "  _177 = torch.add(torch.matmul(input75, CONSTANTS.c169), CONSTANTS.c170)\n",
      "  x50 = torch.add(x45, _177)\n",
      "  input76 = torch.to(x50, 6)\n",
      "  _178 = torch.layer_norm(input76, [256], CONSTANTS.c171, CONSTANTS.c172)\n",
      "  x51 = torch.to(_178, 5)\n",
      "  input77 = torch.transpose(x51, 1, 2)\n",
      "  _179 = torch.conv1d(input77, CONSTANTS.c173, CONSTANTS.c174)\n",
      "  x52 = torch.glu(_179, 1)\n",
      "  input78 = torch.masked_fill(torch.to(x52, 6), _43, 0.)\n",
      "  _180 = torch.conv1d(torch.to(input78, 5), CONSTANTS.c175, CONSTANTS.c176, [1], [15], [1], 256)\n",
      "  input79 = torch.to(_180, 6)\n",
      "  _181 = torch.batch_norm(input79, CONSTANTS.c177, CONSTANTS.c178, CONSTANTS.c179, CONSTANTS.c180, False, 0.10000000000000001, 1.0000000000000001e-05, True)\n",
      "  input80 = torch.to(_181, 5)\n",
      "  input81 = torch.silu(input80)\n",
      "  _182 = torch.conv1d(input81, CONSTANTS.c181, CONSTANTS.c182)\n",
      "  input82 = torch.transpose(_182, 1, 2)\n",
      "  x53 = torch.add(x50, input82)\n",
      "  input83 = torch.to(x53, 6)\n",
      "  _183 = torch.layer_norm(input83, [256], CONSTANTS.c183, CONSTANTS.c184)\n",
      "  input84 = torch.to(_183, 5)\n",
      "  _184 = torch.add(torch.matmul(input84, CONSTANTS.c185), CONSTANTS.c186)\n",
      "  input85 = torch.silu(_184)\n",
      "  _185 = torch.add(torch.matmul(input85, CONSTANTS.c187), CONSTANTS.c188)\n",
      "  x54 = torch.add(x53, torch.mul(_185, CONSTANTS.c20))\n",
      "  input86 = torch.to(x54, 6)\n",
      "  _186 = torch.layer_norm(input86, [256], CONSTANTS.c189, CONSTANTS.c190)\n",
      "  x55 = torch.to(_186, 5)\n",
      "  input87 = torch.to(x55, 6)\n",
      "  _187 = torch.layer_norm(input87, [256], CONSTANTS.c191, CONSTANTS.c192)\n",
      "  input88 = torch.to(_187, 5)\n",
      "  _188 = torch.add(torch.matmul(input88, CONSTANTS.c193), CONSTANTS.c194)\n",
      "  input89 = torch.silu(_188)\n",
      "  _189 = torch.add(torch.matmul(input89, CONSTANTS.c195), CONSTANTS.c196)\n",
      "  x56 = torch.add(x55, torch.mul(_189, CONSTANTS.c20))\n",
      "  input90 = torch.to(x56, 6)\n",
      "  _190 = torch.layer_norm(input90, [256], CONSTANTS.c197, CONSTANTS.c198)\n",
      "  query4 = torch.to(_190, 5)\n",
      "  _191 = torch.size(query4, 0)\n",
      "  _192 = torch.add(torch.matmul(query4, CONSTANTS.c199), CONSTANTS.c200)\n",
      "  _193 = torch.slice(_192, -1, 512, 768)\n",
      "  _194 = torch.slice(_192, -1, 256, 512)\n",
      "  _195 = torch.slice(_192, -1, 0, 256)\n",
      "  _196 = [_191, -1, 4, 64]\n",
      "  q14 = torch.view(_195, _196)\n",
      "  k9 = torch.view(_194, _196)\n",
      "  v4 = torch.view(_193, _196)\n",
      "  q15 = torch.transpose(q14, 1, 2)\n",
      "  k10 = torch.transpose(k9, 1, 2)\n",
      "  value4 = torch.transpose(v4, 1, 2)\n",
      "  q16 = torch.transpose(q15, 1, 2)\n",
      "  p9 = torch.view(torch.matmul(_22, CONSTANTS.c201), _24)\n",
      "  p10 = torch.transpose(p9, 1, 2)\n",
      "  q_with_bias_u4 = torch.transpose(torch.add(q16, CONSTANTS.c202), 1, 2)\n",
      "  q_with_bias_v4 = torch.transpose(torch.add(q16, CONSTANTS.c203), 1, 2)\n",
      "  _197 = torch.transpose(k10, -2, -1)\n",
      "  matrix_ac4 = torch.matmul(torch.to(q_with_bias_u4, 5), _197)\n",
      "  _198 = torch.transpose(p10, -2, -1)\n",
      "  x57 = torch.matmul(torch.to(q_with_bias_v4, 5), _198)\n",
      "  _199 = torch.size(x57, 0)\n",
      "  _200 = torch.size(x57, 1)\n",
      "  _201 = torch.size(x57, 2)\n",
      "  _202 = torch.size(x57, 3)\n",
      "  x58 = torch.constant_pad_nd(x57, [1, 0], 0.)\n",
      "  x59 = torch.view(x58, [_199, _200, -1, _201])\n",
      "  _203 = torch.slice(x59, 0, 0, 9223372036854775807)\n",
      "  _204 = torch.slice(_203, 1, 0, 9223372036854775807)\n",
      "  _205 = torch.slice(_204, 2, 1, 9223372036854775807)\n",
      "  matrix_bd9 = torch.view(_205, [_199, _200, _201, _202])\n",
      "  _206 = torch.size(matrix_ac4, -1)\n",
      "  _207 = torch.slice(matrix_bd9, 0, 0, 9223372036854775807)\n",
      "  _208 = torch.slice(_207, 1, 0, 9223372036854775807)\n",
      "  _209 = torch.slice(_208, 2, 0, 9223372036854775807)\n",
      "  matrix_bd10 = torch.slice(_209, 3, 0, _206)\n",
      "  scores9 = torch.div(torch.add(matrix_ac4, matrix_bd10), CONSTANTS.c28)\n",
      "  _210 = torch.size(value4, 0)\n",
      "  scores10 = torch.masked_fill(scores9, mask0, -10000.)\n",
      "  input91 = torch.masked_fill(torch.softmax(scores10, -1, 6), mask0, 0.)\n",
      "  x60 = torch.matmul(torch.to(input91, 5), value4)\n",
      "  input92 = torch.reshape(torch.transpose(x60, 1, 2), [_210, -1, 256])\n",
      "  _211 = torch.add(torch.matmul(input92, CONSTANTS.c204), CONSTANTS.c205)\n",
      "  x61 = torch.add(x56, _211)\n",
      "  input93 = torch.to(x61, 6)\n",
      "  _212 = torch.layer_norm(input93, [256], CONSTANTS.c206, CONSTANTS.c207)\n",
      "  x62 = torch.to(_212, 5)\n",
      "  input94 = torch.transpose(x62, 1, 2)\n",
      "  _213 = torch.conv1d(input94, CONSTANTS.c208, CONSTANTS.c209)\n",
      "  x63 = torch.glu(_213, 1)\n",
      "  input95 = torch.masked_fill(torch.to(x63, 6), _43, 0.)\n",
      "  _214 = torch.conv1d(torch.to(input95, 5), CONSTANTS.c210, CONSTANTS.c211, [1], [15], [1], 256)\n",
      "  input96 = torch.to(_214, 6)\n",
      "  _215 = torch.batch_norm(input96, CONSTANTS.c212, CONSTANTS.c213, CONSTANTS.c214, CONSTANTS.c215, False, 0.10000000000000001, 1.0000000000000001e-05, True)\n",
      "  input97 = torch.to(_215, 5)\n",
      "  input98 = torch.silu(input97)\n",
      "  _216 = torch.conv1d(input98, CONSTANTS.c216, CONSTANTS.c217)\n",
      "  input99 = torch.transpose(_216, 1, 2)\n",
      "  x64 = torch.add(x61, input99)\n",
      "  input100 = torch.to(x64, 6)\n",
      "  _217 = torch.layer_norm(input100, [256], CONSTANTS.c218, CONSTANTS.c219)\n",
      "  input101 = torch.to(_217, 5)\n",
      "  _218 = torch.matmul(input101, CONSTANTS.c220)\n",
      "  input102 = torch.silu(torch.add(_218, CONSTANTS.c221))\n",
      "  _219 = torch.matmul(input102, CONSTANTS.c222)\n",
      "  _220 = torch.mul(torch.add(_219, CONSTANTS.c223), CONSTANTS.c20)\n",
      "  x65 = torch.add(x64, _220)\n",
      "  input103 = torch.to(x65, 6)\n",
      "  _221 = torch.layer_norm(input103, [256], CONSTANTS.c224, CONSTANTS.c225)\n",
      "  x66 = torch.to(_221, 5)\n",
      "  input104 = torch.to(x66, 6)\n",
      "  _222 = torch.layer_norm(input104, [256], CONSTANTS.c226, CONSTANTS.c227)\n",
      "  input105 = torch.to(_222, 5)\n",
      "  _223 = torch.matmul(input105, CONSTANTS.c228)\n",
      "  input106 = torch.silu(torch.add(_223, CONSTANTS.c229))\n",
      "  _224 = torch.matmul(input106, CONSTANTS.c230)\n",
      "  _225 = torch.mul(torch.add(_224, CONSTANTS.c231), CONSTANTS.c20)\n",
      "  x67 = torch.add(x66, _225)\n",
      "  input107 = torch.to(x67, 6)\n",
      "  _226 = torch.layer_norm(input107, [256], CONSTANTS.c232, CONSTANTS.c233)\n",
      "  query5 = torch.to(_226, 5)\n",
      "  _227 = torch.size(query5, 0)\n",
      "  _228 = torch.add(torch.matmul(query5, CONSTANTS.c234), CONSTANTS.c235)\n",
      "  _229 = torch.slice(_228, -1, 512, 768)\n",
      "  _230 = torch.slice(_228, -1, 256, 512)\n",
      "  _231 = torch.slice(_228, -1, 0, 256)\n",
      "  _232 = [_227, -1, 4, 64]\n",
      "  q17 = torch.view(_231, _232)\n",
      "  k11 = torch.view(_230, _232)\n",
      "  v5 = torch.view(_229, _232)\n",
      "  q18 = torch.transpose(q17, 1, 2)\n",
      "  k12 = torch.transpose(k11, 1, 2)\n",
      "  value5 = torch.transpose(v5, 1, 2)\n",
      "  q19 = torch.transpose(q18, 1, 2)\n",
      "  p11 = torch.view(torch.matmul(_22, CONSTANTS.c236), _24)\n",
      "  p12 = torch.transpose(p11, 1, 2)\n",
      "  q_with_bias_u5 = torch.transpose(torch.add(q19, CONSTANTS.c237), 1, 2)\n",
      "  q_with_bias_v5 = torch.transpose(torch.add(q19, CONSTANTS.c238), 1, 2)\n",
      "  _233 = torch.transpose(k12, -2, -1)\n",
      "  matrix_ac5 = torch.matmul(torch.to(q_with_bias_u5, 5), _233)\n",
      "  _234 = torch.transpose(p12, -2, -1)\n",
      "  x68 = torch.matmul(torch.to(q_with_bias_v5, 5), _234)\n",
      "  _235 = torch.size(x68, 0)\n",
      "  _236 = torch.size(x68, 1)\n",
      "  _237 = torch.size(x68, 2)\n",
      "  _238 = torch.size(x68, 3)\n",
      "  x69 = torch.constant_pad_nd(x68, [1, 0], 0.)\n",
      "  x70 = torch.view(x69, [_235, _236, -1, _237])\n",
      "  _239 = torch.slice(x70, 0, 0, 9223372036854775807)\n",
      "  _240 = torch.slice(_239, 1, 0, 9223372036854775807)\n",
      "  _241 = torch.slice(_240, 2, 1, 9223372036854775807)\n",
      "  matrix_bd11 = torch.view(_241, [_235, _236, _237, _238])\n",
      "  _242 = torch.size(matrix_ac5, -1)\n",
      "  _243 = torch.slice(matrix_bd11, 0, 0, 9223372036854775807)\n",
      "  _244 = torch.slice(_243, 1, 0, 9223372036854775807)\n",
      "  _245 = torch.slice(_244, 2, 0, 9223372036854775807)\n",
      "  matrix_bd12 = torch.slice(_245, 3, 0, _242)\n",
      "  scores11 = torch.div(torch.add(matrix_ac5, matrix_bd12), CONSTANTS.c28)\n",
      "  _246 = torch.size(value5, 0)\n",
      "  scores12 = torch.masked_fill(scores11, mask0, -10000.)\n",
      "  input108 = torch.masked_fill(torch.softmax(scores12, -1, 6), mask0, 0.)\n",
      "  x71 = torch.matmul(torch.to(input108, 5), value5)\n",
      "  input109 = torch.reshape(torch.transpose(x71, 1, 2), [_246, -1, 256])\n",
      "  _247 = torch.matmul(input109, CONSTANTS.c239)\n",
      "  x72 = torch.add(x67, torch.add(_247, CONSTANTS.c240))\n",
      "  input110 = torch.to(x72, 6)\n",
      "  _248 = torch.layer_norm(input110, [256], CONSTANTS.c241, CONSTANTS.c242)\n",
      "  x73 = torch.to(_248, 5)\n",
      "  input111 = torch.transpose(x73, 1, 2)\n",
      "  _249 = torch.conv1d(input111, CONSTANTS.c243, CONSTANTS.c244)\n",
      "  x74 = torch.glu(_249, 1)\n",
      "  input112 = torch.masked_fill(torch.to(x74, 6), _43, 0.)\n",
      "  _250 = torch.conv1d(torch.to(input112, 5), CONSTANTS.c245, CONSTANTS.c246, [1], [15], [1], 256)\n",
      "  input113 = torch.to(_250, 6)\n",
      "  _251 = torch.batch_norm(input113, CONSTANTS.c247, CONSTANTS.c248, CONSTANTS.c249, CONSTANTS.c250, False, 0.10000000000000001, 1.0000000000000001e-05, True)\n",
      "  input114 = torch.to(_251, 5)\n",
      "  input115 = torch.silu(input114)\n",
      "  _252 = torch.conv1d(input115, CONSTANTS.c251, CONSTANTS.c252)\n",
      "  input116 = torch.transpose(_252, 1, 2)\n",
      "  x75 = torch.add(x72, input116)\n",
      "  input117 = torch.to(x75, 6)\n",
      "  _253 = torch.layer_norm(input117, [256], CONSTANTS.c253, CONSTANTS.c254)\n",
      "  input118 = torch.to(_253, 5)\n",
      "  _254 = torch.matmul(input118, CONSTANTS.c255)\n",
      "  input119 = torch.silu(torch.add(_254, CONSTANTS.c256))\n",
      "  _255 = torch.matmul(input119, CONSTANTS.c257)\n",
      "  _256 = torch.mul(torch.add(_255, CONSTANTS.c258), CONSTANTS.c20)\n",
      "  x76 = torch.add(x75, _256)\n",
      "  input120 = torch.to(x76, 6)\n",
      "  _257 = torch.layer_norm(input120, [256], CONSTANTS.c259, CONSTANTS.c260)\n",
      "  x77 = torch.to(_257, 5)\n",
      "  input121 = torch.to(x77, 6)\n",
      "  _258 = torch.layer_norm(input121, [256], CONSTANTS.c261, CONSTANTS.c262)\n",
      "  input122 = torch.to(_258, 5)\n",
      "  _259 = torch.matmul(input122, CONSTANTS.c263)\n",
      "  input123 = torch.silu(torch.add(_259, CONSTANTS.c264))\n",
      "  _260 = torch.matmul(input123, CONSTANTS.c265)\n",
      "  _261 = torch.mul(torch.add(_260, CONSTANTS.c266), CONSTANTS.c20)\n",
      "  x78 = torch.add(x77, _261)\n",
      "  input124 = torch.to(x78, 6)\n",
      "  _262 = torch.layer_norm(input124, [256], CONSTANTS.c267, CONSTANTS.c268)\n",
      "  query6 = torch.to(_262, 5)\n",
      "  _263 = torch.size(query6, 0)\n",
      "  _264 = torch.add(torch.matmul(query6, CONSTANTS.c269), CONSTANTS.c270)\n",
      "  _265 = torch.slice(_264, -1, 512, 768)\n",
      "  _266 = torch.slice(_264, -1, 256, 512)\n",
      "  _267 = torch.slice(_264, -1, 0, 256)\n",
      "  _268 = [_263, -1, 4, 64]\n",
      "  q20 = torch.view(_267, _268)\n",
      "  k13 = torch.view(_266, _268)\n",
      "  v6 = torch.view(_265, _268)\n",
      "  q21 = torch.transpose(q20, 1, 2)\n",
      "  k14 = torch.transpose(k13, 1, 2)\n",
      "  value6 = torch.transpose(v6, 1, 2)\n",
      "  q22 = torch.transpose(q21, 1, 2)\n",
      "  p13 = torch.view(torch.matmul(_22, CONSTANTS.c271), _24)\n",
      "  p14 = torch.transpose(p13, 1, 2)\n",
      "  q_with_bias_u6 = torch.transpose(torch.add(q22, CONSTANTS.c272), 1, 2)\n",
      "  q_with_bias_v6 = torch.transpose(torch.add(q22, CONSTANTS.c273), 1, 2)\n",
      "  _269 = torch.transpose(k14, -2, -1)\n",
      "  matrix_ac6 = torch.matmul(torch.to(q_with_bias_u6, 5), _269)\n",
      "  _270 = torch.transpose(p14, -2, -1)\n",
      "  x79 = torch.matmul(torch.to(q_with_bias_v6, 5), _270)\n",
      "  _271 = torch.size(x79, 0)\n",
      "  _272 = torch.size(x79, 1)\n",
      "  _273 = torch.size(x79, 2)\n",
      "  _274 = torch.size(x79, 3)\n",
      "  x80 = torch.constant_pad_nd(x79, [1, 0], 0.)\n",
      "  x81 = torch.view(x80, [_271, _272, -1, _273])\n",
      "  _275 = torch.slice(x81, 0, 0, 9223372036854775807)\n",
      "  _276 = torch.slice(_275, 1, 0, 9223372036854775807)\n",
      "  _277 = torch.slice(_276, 2, 1, 9223372036854775807)\n",
      "  matrix_bd13 = torch.view(_277, [_271, _272, _273, _274])\n",
      "  _278 = torch.size(matrix_ac6, -1)\n",
      "  _279 = torch.slice(matrix_bd13, 0, 0, 9223372036854775807)\n",
      "  _280 = torch.slice(_279, 1, 0, 9223372036854775807)\n",
      "  _281 = torch.slice(_280, 2, 0, 9223372036854775807)\n",
      "  matrix_bd14 = torch.slice(_281, 3, 0, _278)\n",
      "  scores13 = torch.div(torch.add(matrix_ac6, matrix_bd14), CONSTANTS.c28)\n",
      "  _282 = torch.size(value6, 0)\n",
      "  scores14 = torch.masked_fill(scores13, mask0, -10000.)\n",
      "  input125 = torch.masked_fill(torch.softmax(scores14, -1, 6), mask0, 0.)\n",
      "  x82 = torch.matmul(torch.to(input125, 5), value6)\n",
      "  input126 = torch.reshape(torch.transpose(x82, 1, 2), [_282, -1, 256])\n",
      "  _283 = torch.matmul(input126, CONSTANTS.c274)\n",
      "  x83 = torch.add(x78, torch.add(_283, CONSTANTS.c275))\n",
      "  input127 = torch.to(x83, 6)\n",
      "  _284 = torch.layer_norm(input127, [256], CONSTANTS.c276, CONSTANTS.c277)\n",
      "  x84 = torch.to(_284, 5)\n",
      "  input128 = torch.transpose(x84, 1, 2)\n",
      "  _285 = torch.conv1d(input128, CONSTANTS.c278, CONSTANTS.c279)\n",
      "  x85 = torch.glu(_285, 1)\n",
      "  input129 = torch.masked_fill(torch.to(x85, 6), _43, 0.)\n",
      "  _286 = torch.conv1d(torch.to(input129, 5), CONSTANTS.c280, CONSTANTS.c281, [1], [15], [1], 256)\n",
      "  input130 = torch.to(_286, 6)\n",
      "  _287 = torch.batch_norm(input130, CONSTANTS.c282, CONSTANTS.c283, CONSTANTS.c284, CONSTANTS.c285, False, 0.10000000000000001, 1.0000000000000001e-05, True)\n",
      "  input131 = torch.to(_287, 5)\n",
      "  input132 = torch.silu(input131)\n",
      "  _288 = torch.conv1d(input132, CONSTANTS.c286, CONSTANTS.c287)\n",
      "  input133 = torch.transpose(_288, 1, 2)\n",
      "  x86 = torch.add(x83, input133)\n",
      "  input134 = torch.to(x86, 6)\n",
      "  _289 = torch.layer_norm(input134, [256], CONSTANTS.c288, CONSTANTS.c289)\n",
      "  input135 = torch.to(_289, 5)\n",
      "  _290 = torch.matmul(input135, CONSTANTS.c290)\n",
      "  input136 = torch.silu(torch.add(_290, CONSTANTS.c291))\n",
      "  _291 = torch.matmul(input136, CONSTANTS.c292)\n",
      "  _292 = torch.mul(torch.add(_291, CONSTANTS.c293), CONSTANTS.c20)\n",
      "  x87 = torch.add(x86, _292)\n",
      "  input137 = torch.to(x87, 6)\n",
      "  _293 = torch.layer_norm(input137, [256], CONSTANTS.c294, CONSTANTS.c295)\n",
      "  x88 = torch.to(_293, 5)\n",
      "  input138 = torch.to(x88, 6)\n",
      "  _294 = torch.layer_norm(input138, [256], CONSTANTS.c296, CONSTANTS.c297)\n",
      "  input139 = torch.to(_294, 5)\n",
      "  _295 = torch.matmul(input139, CONSTANTS.c298)\n",
      "  input140 = torch.silu(torch.add(_295, CONSTANTS.c299))\n",
      "  _296 = torch.matmul(input140, CONSTANTS.c300)\n",
      "  _297 = torch.mul(torch.add(_296, CONSTANTS.c301), CONSTANTS.c20)\n",
      "  x89 = torch.add(x88, _297)\n",
      "  input141 = torch.to(x89, 6)\n",
      "  _298 = torch.layer_norm(input141, [256], CONSTANTS.c302, CONSTANTS.c303)\n",
      "  query7 = torch.to(_298, 5)\n",
      "  _299 = torch.size(query7, 0)\n",
      "  _300 = torch.add(torch.matmul(query7, CONSTANTS.c304), CONSTANTS.c305)\n",
      "  _301 = torch.slice(_300, -1, 512, 768)\n",
      "  _302 = torch.slice(_300, -1, 256, 512)\n",
      "  _303 = torch.slice(_300, -1, 0, 256)\n",
      "  _304 = [_299, -1, 4, 64]\n",
      "  q23 = torch.view(_303, _304)\n",
      "  k15 = torch.view(_302, _304)\n",
      "  v7 = torch.view(_301, _304)\n",
      "  q24 = torch.transpose(q23, 1, 2)\n",
      "  k16 = torch.transpose(k15, 1, 2)\n",
      "  value7 = torch.transpose(v7, 1, 2)\n",
      "  q25 = torch.transpose(q24, 1, 2)\n",
      "  p15 = torch.view(torch.matmul(_22, CONSTANTS.c306), _24)\n",
      "  p16 = torch.transpose(p15, 1, 2)\n",
      "  q_with_bias_u7 = torch.transpose(torch.add(q25, CONSTANTS.c307), 1, 2)\n",
      "  q_with_bias_v7 = torch.transpose(torch.add(q25, CONSTANTS.c308), 1, 2)\n",
      "  _305 = torch.transpose(k16, -2, -1)\n",
      "  matrix_ac7 = torch.matmul(torch.to(q_with_bias_u7, 5), _305)\n",
      "  _306 = torch.transpose(p16, -2, -1)\n",
      "  x90 = torch.matmul(torch.to(q_with_bias_v7, 5), _306)\n",
      "  _307 = torch.size(x90, 0)\n",
      "  _308 = torch.size(x90, 1)\n",
      "  _309 = torch.size(x90, 2)\n",
      "  _310 = torch.size(x90, 3)\n",
      "  x91 = torch.constant_pad_nd(x90, [1, 0], 0.)\n",
      "  x92 = torch.view(x91, [_307, _308, -1, _309])\n",
      "  _311 = torch.slice(x92, 0, 0, 9223372036854775807)\n",
      "  _312 = torch.slice(_311, 1, 0, 9223372036854775807)\n",
      "  _313 = torch.slice(_312, 2, 1, 9223372036854775807)\n",
      "  matrix_bd15 = torch.view(_313, [_307, _308, _309, _310])\n",
      "  _314 = torch.size(matrix_ac7, -1)\n",
      "  _315 = torch.slice(matrix_bd15, 0, 0, 9223372036854775807)\n",
      "  _316 = torch.slice(_315, 1, 0, 9223372036854775807)\n",
      "  _317 = torch.slice(_316, 2, 0, 9223372036854775807)\n",
      "  matrix_bd16 = torch.slice(_317, 3, 0, _314)\n",
      "  scores15 = torch.div(torch.add(matrix_ac7, matrix_bd16), CONSTANTS.c28)\n",
      "  _318 = torch.size(value7, 0)\n",
      "  scores16 = torch.masked_fill(scores15, mask0, -10000.)\n",
      "  input142 = torch.masked_fill(torch.softmax(scores16, -1, 6), mask0, 0.)\n",
      "  x93 = torch.matmul(torch.to(input142, 5), value7)\n",
      "  input143 = torch.reshape(torch.transpose(x93, 1, 2), [_318, -1, 256])\n",
      "  _319 = torch.matmul(input143, CONSTANTS.c309)\n",
      "  x94 = torch.add(x89, torch.add(_319, CONSTANTS.c310))\n",
      "  input144 = torch.to(x94, 6)\n",
      "  _320 = torch.layer_norm(input144, [256], CONSTANTS.c311, CONSTANTS.c312)\n",
      "  x95 = torch.to(_320, 5)\n",
      "  input145 = torch.transpose(x95, 1, 2)\n",
      "  _321 = torch.conv1d(input145, CONSTANTS.c313, CONSTANTS.c314)\n",
      "  x96 = torch.glu(_321, 1)\n",
      "  input146 = torch.masked_fill(torch.to(x96, 6), _43, 0.)\n",
      "  _322 = torch.conv1d(torch.to(input146, 5), CONSTANTS.c315, CONSTANTS.c316, [1], [15], [1], 256)\n",
      "  input147 = torch.to(_322, 6)\n",
      "  _323 = torch.batch_norm(input147, CONSTANTS.c317, CONSTANTS.c318, CONSTANTS.c319, CONSTANTS.c320, False, 0.10000000000000001, 1.0000000000000001e-05, True)\n",
      "  input148 = torch.to(_323, 5)\n",
      "  input149 = torch.silu(input148)\n",
      "  _324 = torch.conv1d(input149, CONSTANTS.c321, CONSTANTS.c322)\n",
      "  input150 = torch.transpose(_324, 1, 2)\n",
      "  x97 = torch.add(x94, input150)\n",
      "  input151 = torch.to(x97, 6)\n",
      "  _325 = torch.layer_norm(input151, [256], CONSTANTS.c323, CONSTANTS.c324)\n",
      "  input152 = torch.to(_325, 5)\n",
      "  _326 = torch.matmul(input152, CONSTANTS.c325)\n",
      "  input153 = torch.silu(torch.add(_326, CONSTANTS.c326))\n",
      "  _327 = torch.matmul(input153, CONSTANTS.c327)\n",
      "  _328 = torch.mul(torch.add(_327, CONSTANTS.c328), CONSTANTS.c20)\n",
      "  x98 = torch.add(x97, _328)\n",
      "  input154 = torch.to(x98, 6)\n",
      "  _329 = torch.layer_norm(input154, [256], CONSTANTS.c329, CONSTANTS.c330)\n",
      "  x99 = torch.to(_329, 5)\n",
      "  input155 = torch.to(x99, 6)\n",
      "  _330 = torch.layer_norm(input155, [256], CONSTANTS.c331, CONSTANTS.c332)\n",
      "  input156 = torch.to(_330, 5)\n",
      "  _331 = torch.matmul(input156, CONSTANTS.c333)\n",
      "  input157 = torch.silu(torch.add(_331, CONSTANTS.c334))\n",
      "  _332 = torch.matmul(input157, CONSTANTS.c335)\n",
      "  _333 = torch.mul(torch.add(_332, CONSTANTS.c336), CONSTANTS.c20)\n",
      "  x100 = torch.add(x99, _333)\n",
      "  input158 = torch.to(x100, 6)\n",
      "  _334 = torch.layer_norm(input158, [256], CONSTANTS.c337, CONSTANTS.c338)\n",
      "  query8 = torch.to(_334, 5)\n",
      "  _335 = torch.size(query8, 0)\n",
      "  _336 = torch.add(torch.matmul(query8, CONSTANTS.c339), CONSTANTS.c340)\n",
      "  _337 = torch.slice(_336, -1, 512, 768)\n",
      "  _338 = torch.slice(_336, -1, 256, 512)\n",
      "  _339 = torch.slice(_336, -1, 0, 256)\n",
      "  _340 = [_335, -1, 4, 64]\n",
      "  q26 = torch.view(_339, _340)\n",
      "  k17 = torch.view(_338, _340)\n",
      "  v8 = torch.view(_337, _340)\n",
      "  q27 = torch.transpose(q26, 1, 2)\n",
      "  k18 = torch.transpose(k17, 1, 2)\n",
      "  value8 = torch.transpose(v8, 1, 2)\n",
      "  q28 = torch.transpose(q27, 1, 2)\n",
      "  p17 = torch.view(torch.matmul(_22, CONSTANTS.c341), _24)\n",
      "  p18 = torch.transpose(p17, 1, 2)\n",
      "  q_with_bias_u8 = torch.transpose(torch.add(q28, CONSTANTS.c342), 1, 2)\n",
      "  q_with_bias_v8 = torch.transpose(torch.add(q28, CONSTANTS.c343), 1, 2)\n",
      "  _341 = torch.transpose(k18, -2, -1)\n",
      "  matrix_ac8 = torch.matmul(torch.to(q_with_bias_u8, 5), _341)\n",
      "  _342 = torch.transpose(p18, -2, -1)\n",
      "  x101 = torch.matmul(torch.to(q_with_bias_v8, 5), _342)\n",
      "  _343 = torch.size(x101, 0)\n",
      "  _344 = torch.size(x101, 1)\n",
      "  _345 = torch.size(x101, 2)\n",
      "  _346 = torch.size(x101, 3)\n",
      "  x102 = torch.constant_pad_nd(x101, [1, 0], 0.)\n",
      "  x103 = torch.view(x102, [_343, _344, -1, _345])\n",
      "  _347 = torch.slice(x103, 0, 0, 9223372036854775807)\n",
      "  _348 = torch.slice(_347, 1, 0, 9223372036854775807)\n",
      "  _349 = torch.slice(_348, 2, 1, 9223372036854775807)\n",
      "  matrix_bd17 = torch.view(_349, [_343, _344, _345, _346])\n",
      "  _350 = torch.size(matrix_ac8, -1)\n",
      "  _351 = torch.slice(matrix_bd17, 0, 0, 9223372036854775807)\n",
      "  _352 = torch.slice(_351, 1, 0, 9223372036854775807)\n",
      "  _353 = torch.slice(_352, 2, 0, 9223372036854775807)\n",
      "  matrix_bd18 = torch.slice(_353, 3, 0, _350)\n",
      "  scores17 = torch.div(torch.add(matrix_ac8, matrix_bd18), CONSTANTS.c28)\n",
      "  _354 = torch.size(value8, 0)\n",
      "  scores18 = torch.masked_fill(scores17, mask0, -10000.)\n",
      "  input159 = torch.masked_fill(torch.softmax(scores18, -1, 6), mask0, 0.)\n",
      "  x104 = torch.matmul(torch.to(input159, 5), value8)\n",
      "  input160 = torch.reshape(torch.transpose(x104, 1, 2), [_354, -1, 256])\n",
      "  _355 = torch.matmul(input160, CONSTANTS.c344)\n",
      "  x105 = torch.add(x100, torch.add(_355, CONSTANTS.c345))\n",
      "  input161 = torch.to(x105, 6)\n",
      "  _356 = torch.layer_norm(input161, [256], CONSTANTS.c346, CONSTANTS.c347)\n",
      "  x106 = torch.to(_356, 5)\n",
      "  input162 = torch.transpose(x106, 1, 2)\n",
      "  _357 = torch.conv1d(input162, CONSTANTS.c348, CONSTANTS.c349)\n",
      "  x107 = torch.glu(_357, 1)\n",
      "  input163 = torch.masked_fill(torch.to(x107, 6), _43, 0.)\n",
      "  _358 = torch.conv1d(torch.to(input163, 5), CONSTANTS.c350, CONSTANTS.c351, [1], [15], [1], 256)\n",
      "  input164 = torch.to(_358, 6)\n",
      "  _359 = torch.batch_norm(input164, CONSTANTS.c352, CONSTANTS.c353, CONSTANTS.c354, CONSTANTS.c355, False, 0.10000000000000001, 1.0000000000000001e-05, True)\n",
      "  input165 = torch.to(_359, 5)\n",
      "  input166 = torch.silu(input165)\n",
      "  _360 = torch.conv1d(input166, CONSTANTS.c356, CONSTANTS.c357)\n",
      "  input167 = torch.transpose(_360, 1, 2)\n",
      "  x108 = torch.add(x105, input167)\n",
      "  input168 = torch.to(x108, 6)\n",
      "  _361 = torch.layer_norm(input168, [256], CONSTANTS.c358, CONSTANTS.c359)\n",
      "  input169 = torch.to(_361, 5)\n",
      "  _362 = torch.matmul(input169, CONSTANTS.c360)\n",
      "  input170 = torch.silu(torch.add(_362, CONSTANTS.c361))\n",
      "  _363 = torch.matmul(input170, CONSTANTS.c362)\n",
      "  _364 = torch.mul(torch.add(_363, CONSTANTS.c363), CONSTANTS.c20)\n",
      "  x109 = torch.add(x108, _364)\n",
      "  input171 = torch.to(x109, 6)\n",
      "  _365 = torch.layer_norm(input171, [256], CONSTANTS.c364, CONSTANTS.c365)\n",
      "  x110 = torch.to(_365, 5)\n",
      "  input172 = torch.to(x110, 6)\n",
      "  _366 = torch.layer_norm(input172, [256], CONSTANTS.c366, CONSTANTS.c367)\n",
      "  input173 = torch.to(_366, 5)\n",
      "  _367 = torch.matmul(input173, CONSTANTS.c368)\n",
      "  input174 = torch.silu(torch.add(_367, CONSTANTS.c369))\n",
      "  _368 = torch.matmul(input174, CONSTANTS.c370)\n",
      "  _369 = torch.mul(torch.add(_368, CONSTANTS.c371), CONSTANTS.c20)\n",
      "  x111 = torch.add(x110, _369)\n",
      "  input175 = torch.to(x111, 6)\n",
      "  _370 = torch.layer_norm(input175, [256], CONSTANTS.c372, CONSTANTS.c373)\n",
      "  query9 = torch.to(_370, 5)\n",
      "  _371 = torch.size(query9, 0)\n",
      "  _372 = torch.add(torch.matmul(query9, CONSTANTS.c374), CONSTANTS.c375)\n",
      "  _373 = torch.slice(_372, -1, 512, 768)\n",
      "  _374 = torch.slice(_372, -1, 256, 512)\n",
      "  _375 = torch.slice(_372, -1, 0, 256)\n",
      "  _376 = [_371, -1, 4, 64]\n",
      "  q29 = torch.view(_375, _376)\n",
      "  k19 = torch.view(_374, _376)\n",
      "  v9 = torch.view(_373, _376)\n",
      "  q30 = torch.transpose(q29, 1, 2)\n",
      "  k20 = torch.transpose(k19, 1, 2)\n",
      "  value9 = torch.transpose(v9, 1, 2)\n",
      "  q31 = torch.transpose(q30, 1, 2)\n",
      "  p19 = torch.view(torch.matmul(_22, CONSTANTS.c376), _24)\n",
      "  p20 = torch.transpose(p19, 1, 2)\n",
      "  q_with_bias_u9 = torch.transpose(torch.add(q31, CONSTANTS.c377), 1, 2)\n",
      "  q_with_bias_v9 = torch.transpose(torch.add(q31, CONSTANTS.c378), 1, 2)\n",
      "  _377 = torch.transpose(k20, -2, -1)\n",
      "  matrix_ac9 = torch.matmul(torch.to(q_with_bias_u9, 5), _377)\n",
      "  _378 = torch.transpose(p20, -2, -1)\n",
      "  x112 = torch.matmul(torch.to(q_with_bias_v9, 5), _378)\n",
      "  _379 = torch.size(x112, 0)\n",
      "  _380 = torch.size(x112, 1)\n",
      "  _381 = torch.size(x112, 2)\n",
      "  _382 = torch.size(x112, 3)\n",
      "  x113 = torch.constant_pad_nd(x112, [1, 0], 0.)\n",
      "  x114 = torch.view(x113, [_379, _380, -1, _381])\n",
      "  _383 = torch.slice(x114, 0, 0, 9223372036854775807)\n",
      "  _384 = torch.slice(_383, 1, 0, 9223372036854775807)\n",
      "  _385 = torch.slice(_384, 2, 1, 9223372036854775807)\n",
      "  matrix_bd19 = torch.view(_385, [_379, _380, _381, _382])\n",
      "  _386 = torch.size(matrix_ac9, -1)\n",
      "  _387 = torch.slice(matrix_bd19, 0, 0, 9223372036854775807)\n",
      "  _388 = torch.slice(_387, 1, 0, 9223372036854775807)\n",
      "  _389 = torch.slice(_388, 2, 0, 9223372036854775807)\n",
      "  matrix_bd20 = torch.slice(_389, 3, 0, _386)\n",
      "  scores19 = torch.div(torch.add(matrix_ac9, matrix_bd20), CONSTANTS.c28)\n",
      "  _390 = torch.size(value9, 0)\n",
      "  scores20 = torch.masked_fill(scores19, mask0, -10000.)\n",
      "  input176 = torch.masked_fill(torch.softmax(scores20, -1, 6), mask0, 0.)\n",
      "  x115 = torch.matmul(torch.to(input176, 5), value9)\n",
      "  input177 = torch.reshape(torch.transpose(x115, 1, 2), [_390, -1, 256])\n",
      "  _391 = torch.matmul(input177, CONSTANTS.c379)\n",
      "  x116 = torch.add(x111, torch.add(_391, CONSTANTS.c380))\n",
      "  input178 = torch.to(x116, 6)\n",
      "  _392 = torch.layer_norm(input178, [256], CONSTANTS.c381, CONSTANTS.c382)\n",
      "  x117 = torch.to(_392, 5)\n",
      "  input179 = torch.transpose(x117, 1, 2)\n",
      "  _393 = torch.conv1d(input179, CONSTANTS.c383, CONSTANTS.c384)\n",
      "  x118 = torch.glu(_393, 1)\n",
      "  input180 = torch.masked_fill(torch.to(x118, 6), _43, 0.)\n",
      "  _394 = torch.conv1d(torch.to(input180, 5), CONSTANTS.c385, CONSTANTS.c386, [1], [15], [1], 256)\n",
      "  input181 = torch.to(_394, 6)\n",
      "  _395 = torch.batch_norm(input181, CONSTANTS.c387, CONSTANTS.c388, CONSTANTS.c389, CONSTANTS.c390, False, 0.10000000000000001, 1.0000000000000001e-05, True)\n",
      "  input182 = torch.to(_395, 5)\n",
      "  input183 = torch.silu(input182)\n",
      "  _396 = torch.conv1d(input183, CONSTANTS.c391, CONSTANTS.c392)\n",
      "  input184 = torch.transpose(_396, 1, 2)\n",
      "  x119 = torch.add(x116, input184)\n",
      "  input185 = torch.to(x119, 6)\n",
      "  _397 = torch.layer_norm(input185, [256], CONSTANTS.c393, CONSTANTS.c394)\n",
      "  input186 = torch.to(_397, 5)\n",
      "  _398 = torch.matmul(input186, CONSTANTS.c395)\n",
      "  input187 = torch.silu(torch.add(_398, CONSTANTS.c396))\n",
      "  _399 = torch.matmul(input187, CONSTANTS.c397)\n",
      "  _400 = torch.mul(torch.add(_399, CONSTANTS.c398), CONSTANTS.c20)\n",
      "  x120 = torch.add(x119, _400)\n",
      "  input188 = torch.to(x120, 6)\n",
      "  _401 = torch.layer_norm(input188, [256], CONSTANTS.c399, CONSTANTS.c400)\n",
      "  x121 = torch.to(_401, 5)\n",
      "  input189 = torch.to(x121, 6)\n",
      "  _402 = torch.layer_norm(input189, [256], CONSTANTS.c401, CONSTANTS.c402)\n",
      "  input190 = torch.to(_402, 5)\n",
      "  _403 = torch.matmul(input190, CONSTANTS.c403)\n",
      "  input191 = torch.silu(torch.add(_403, CONSTANTS.c404))\n",
      "  _404 = torch.matmul(input191, CONSTANTS.c405)\n",
      "  _405 = torch.mul(torch.add(_404, CONSTANTS.c406), CONSTANTS.c20)\n",
      "  x122 = torch.add(x121, _405)\n",
      "  input192 = torch.to(x122, 6)\n",
      "  _406 = torch.layer_norm(input192, [256], CONSTANTS.c407, CONSTANTS.c408)\n",
      "  query10 = torch.to(_406, 5)\n",
      "  _407 = torch.size(query10, 0)\n",
      "  _408 = torch.add(torch.matmul(query10, CONSTANTS.c409), CONSTANTS.c410)\n",
      "  _409 = torch.slice(_408, -1, 512, 768)\n",
      "  _410 = torch.slice(_408, -1, 256, 512)\n",
      "  _411 = torch.slice(_408, -1, 0, 256)\n",
      "  _412 = [_407, -1, 4, 64]\n",
      "  q32 = torch.view(_411, _412)\n",
      "  k21 = torch.view(_410, _412)\n",
      "  v10 = torch.view(_409, _412)\n",
      "  q33 = torch.transpose(q32, 1, 2)\n",
      "  k22 = torch.transpose(k21, 1, 2)\n",
      "  value10 = torch.transpose(v10, 1, 2)\n",
      "  q34 = torch.transpose(q33, 1, 2)\n",
      "  p21 = torch.view(torch.matmul(_22, CONSTANTS.c411), _24)\n",
      "  p22 = torch.transpose(p21, 1, 2)\n",
      "  q_with_bias_u10 = torch.transpose(torch.add(q34, CONSTANTS.c412), 1, 2)\n",
      "  q_with_bias_v10 = torch.transpose(torch.add(q34, CONSTANTS.c413), 1, 2)\n",
      "  _413 = torch.transpose(k22, -2, -1)\n",
      "  matrix_ac10 = torch.matmul(torch.to(q_with_bias_u10, 5), _413)\n",
      "  _414 = torch.transpose(p22, -2, -1)\n",
      "  x123 = torch.matmul(torch.to(q_with_bias_v10, 5), _414)\n",
      "  _415 = torch.size(x123, 0)\n",
      "  _416 = torch.size(x123, 1)\n",
      "  _417 = torch.size(x123, 2)\n",
      "  _418 = torch.size(x123, 3)\n",
      "  x124 = torch.constant_pad_nd(x123, [1, 0], 0.)\n",
      "  x125 = torch.view(x124, [_415, _416, -1, _417])\n",
      "  _419 = torch.slice(x125, 0, 0, 9223372036854775807)\n",
      "  _420 = torch.slice(_419, 1, 0, 9223372036854775807)\n",
      "  _421 = torch.slice(_420, 2, 1, 9223372036854775807)\n",
      "  matrix_bd21 = torch.view(_421, [_415, _416, _417, _418])\n",
      "  _422 = torch.size(matrix_ac10, -1)\n",
      "  _423 = torch.slice(matrix_bd21, 0, 0, 9223372036854775807)\n",
      "  _424 = torch.slice(_423, 1, 0, 9223372036854775807)\n",
      "  _425 = torch.slice(_424, 2, 0, 9223372036854775807)\n",
      "  matrix_bd22 = torch.slice(_425, 3, 0, _422)\n",
      "  scores21 = torch.div(torch.add(matrix_ac10, matrix_bd22), CONSTANTS.c28)\n",
      "  _426 = torch.size(value10, 0)\n",
      "  scores22 = torch.masked_fill(scores21, mask0, -10000.)\n",
      "  input193 = torch.masked_fill(torch.softmax(scores22, -1, 6), mask0, 0.)\n",
      "  x126 = torch.matmul(torch.to(input193, 5), value10)\n",
      "  input194 = torch.reshape(torch.transpose(x126, 1, 2), [_426, -1, 256])\n",
      "  _427 = torch.matmul(input194, CONSTANTS.c414)\n",
      "  x127 = torch.add(x122, torch.add(_427, CONSTANTS.c415))\n",
      "  input195 = torch.to(x127, 6)\n",
      "  _428 = torch.layer_norm(input195, [256], CONSTANTS.c416, CONSTANTS.c417)\n",
      "  x128 = torch.to(_428, 5)\n",
      "  input196 = torch.transpose(x128, 1, 2)\n",
      "  _429 = torch.conv1d(input196, CONSTANTS.c418, CONSTANTS.c419)\n",
      "  x129 = torch.glu(_429, 1)\n",
      "  input197 = torch.masked_fill(torch.to(x129, 6), _43, 0.)\n",
      "  _430 = torch.conv1d(torch.to(input197, 5), CONSTANTS.c420, CONSTANTS.c421, [1], [15], [1], 256)\n",
      "  input198 = torch.to(_430, 6)\n",
      "  _431 = torch.batch_norm(input198, CONSTANTS.c422, CONSTANTS.c423, CONSTANTS.c424, CONSTANTS.c425, False, 0.10000000000000001, 1.0000000000000001e-05, True)\n",
      "  input199 = torch.to(_431, 5)\n",
      "  input200 = torch.silu(input199)\n",
      "  _432 = torch.conv1d(input200, CONSTANTS.c426, CONSTANTS.c427)\n",
      "  input201 = torch.transpose(_432, 1, 2)\n",
      "  x130 = torch.add(x127, input201)\n",
      "  input202 = torch.to(x130, 6)\n",
      "  _433 = torch.layer_norm(input202, [256], CONSTANTS.c428, CONSTANTS.c429)\n",
      "  input203 = torch.to(_433, 5)\n",
      "  _434 = torch.matmul(input203, CONSTANTS.c430)\n",
      "  input204 = torch.silu(torch.add(_434, CONSTANTS.c431))\n",
      "  _435 = torch.matmul(input204, CONSTANTS.c432)\n",
      "  _436 = torch.mul(torch.add(_435, CONSTANTS.c433), CONSTANTS.c20)\n",
      "  x131 = torch.add(x130, _436)\n",
      "  input205 = torch.to(x131, 6)\n",
      "  _437 = torch.layer_norm(input205, [256], CONSTANTS.c434, CONSTANTS.c435)\n",
      "  x132 = torch.to(_437, 5)\n",
      "  input206 = torch.to(x132, 6)\n",
      "  _438 = torch.layer_norm(input206, [256], CONSTANTS.c436, CONSTANTS.c437)\n",
      "  input207 = torch.to(_438, 5)\n",
      "  _439 = torch.matmul(input207, CONSTANTS.c438)\n",
      "  input208 = torch.silu(torch.add(_439, CONSTANTS.c439))\n",
      "  _440 = torch.matmul(input208, CONSTANTS.c440)\n",
      "  _441 = torch.mul(torch.add(_440, CONSTANTS.c441), CONSTANTS.c20)\n",
      "  x133 = torch.add(x132, _441)\n",
      "  input209 = torch.to(x133, 6)\n",
      "  _442 = torch.layer_norm(input209, [256], CONSTANTS.c442, CONSTANTS.c443)\n",
      "  query11 = torch.to(_442, 5)\n",
      "  _443 = torch.size(query11, 0)\n",
      "  _444 = torch.add(torch.matmul(query11, CONSTANTS.c444), CONSTANTS.c445)\n",
      "  _445 = torch.slice(_444, -1, 512, 768)\n",
      "  _446 = torch.slice(_444, -1, 256, 512)\n",
      "  _447 = torch.slice(_444, -1, 0, 256)\n",
      "  _448 = [_443, -1, 4, 64]\n",
      "  q35 = torch.view(_447, _448)\n",
      "  k23 = torch.view(_446, _448)\n",
      "  v11 = torch.view(_445, _448)\n",
      "  q36 = torch.transpose(q35, 1, 2)\n",
      "  k24 = torch.transpose(k23, 1, 2)\n",
      "  value11 = torch.transpose(v11, 1, 2)\n",
      "  q37 = torch.transpose(q36, 1, 2)\n",
      "  p23 = torch.view(torch.matmul(_22, CONSTANTS.c446), _24)\n",
      "  p24 = torch.transpose(p23, 1, 2)\n",
      "  q_with_bias_u11 = torch.transpose(torch.add(q37, CONSTANTS.c447), 1, 2)\n",
      "  q_with_bias_v11 = torch.transpose(torch.add(q37, CONSTANTS.c448), 1, 2)\n",
      "  _449 = torch.transpose(k24, -2, -1)\n",
      "  matrix_ac11 = torch.matmul(torch.to(q_with_bias_u11, 5), _449)\n",
      "  _450 = torch.transpose(p24, -2, -1)\n",
      "  x134 = torch.matmul(torch.to(q_with_bias_v11, 5), _450)\n",
      "  _451 = torch.size(x134, 0)\n",
      "  _452 = torch.size(x134, 1)\n",
      "  _453 = torch.size(x134, 2)\n",
      "  _454 = torch.size(x134, 3)\n",
      "  x135 = torch.constant_pad_nd(x134, [1, 0], 0.)\n",
      "  x136 = torch.view(x135, [_451, _452, -1, _453])\n",
      "  _455 = torch.slice(x136, 0, 0, 9223372036854775807)\n",
      "  _456 = torch.slice(_455, 1, 0, 9223372036854775807)\n",
      "  _457 = torch.slice(_456, 2, 1, 9223372036854775807)\n",
      "  matrix_bd23 = torch.view(_457, [_451, _452, _453, _454])\n",
      "  _458 = torch.size(matrix_ac11, -1)\n",
      "  _459 = torch.slice(matrix_bd23, 0, 0, 9223372036854775807)\n",
      "  _460 = torch.slice(_459, 1, 0, 9223372036854775807)\n",
      "  _461 = torch.slice(_460, 2, 0, 9223372036854775807)\n",
      "  matrix_bd24 = torch.slice(_461, 3, 0, _458)\n",
      "  scores23 = torch.div(torch.add(matrix_ac11, matrix_bd24), CONSTANTS.c28)\n",
      "  _462 = torch.size(value11, 0)\n",
      "  scores24 = torch.masked_fill(scores23, mask0, -10000.)\n",
      "  input210 = torch.masked_fill(torch.softmax(scores24, -1, 6), mask0, 0.)\n",
      "  x137 = torch.matmul(torch.to(input210, 5), value11)\n",
      "  input211 = torch.reshape(torch.transpose(x137, 1, 2), [_462, -1, 256])\n",
      "  _463 = torch.matmul(input211, CONSTANTS.c449)\n",
      "  x138 = torch.add(x133, torch.add(_463, CONSTANTS.c450))\n",
      "  input212 = torch.to(x138, 6)\n",
      "  _464 = torch.layer_norm(input212, [256], CONSTANTS.c451, CONSTANTS.c452)\n",
      "  x139 = torch.to(_464, 5)\n",
      "  input213 = torch.transpose(x139, 1, 2)\n",
      "  _465 = torch.conv1d(input213, CONSTANTS.c453, CONSTANTS.c454)\n",
      "  x140 = torch.glu(_465, 1)\n",
      "  input214 = torch.masked_fill(torch.to(x140, 6), _43, 0.)\n",
      "  _466 = torch.conv1d(torch.to(input214, 5), CONSTANTS.c455, CONSTANTS.c456, [1], [15], [1], 256)\n",
      "  input215 = torch.to(_466, 6)\n",
      "  _467 = torch.batch_norm(input215, CONSTANTS.c457, CONSTANTS.c458, CONSTANTS.c459, CONSTANTS.c460, False, 0.10000000000000001, 1.0000000000000001e-05, True)\n",
      "  input216 = torch.to(_467, 5)\n",
      "  input217 = torch.silu(input216)\n",
      "  _468 = torch.conv1d(input217, CONSTANTS.c461, CONSTANTS.c462)\n",
      "  input218 = torch.transpose(_468, 1, 2)\n",
      "  x141 = torch.add(x138, input218)\n",
      "  input219 = torch.to(x141, 6)\n",
      "  _469 = torch.layer_norm(input219, [256], CONSTANTS.c463, CONSTANTS.c464)\n",
      "  input220 = torch.to(_469, 5)\n",
      "  _470 = torch.matmul(input220, CONSTANTS.c465)\n",
      "  input221 = torch.silu(torch.add(_470, CONSTANTS.c466))\n",
      "  _471 = torch.matmul(input221, CONSTANTS.c467)\n",
      "  _472 = torch.mul(torch.add(_471, CONSTANTS.c468), CONSTANTS.c20)\n",
      "  x142 = torch.add(x141, _472)\n",
      "  input222 = torch.to(x142, 6)\n",
      "  _473 = torch.layer_norm(input222, [256], CONSTANTS.c469, CONSTANTS.c470)\n",
      "  x143 = torch.to(_473, 5)\n",
      "  input223 = torch.to(x143, 6)\n",
      "  _474 = torch.layer_norm(input223, [256], CONSTANTS.c471, CONSTANTS.c472)\n",
      "  input224 = torch.to(_474, 5)\n",
      "  _475 = torch.matmul(input224, CONSTANTS.c473)\n",
      "  input225 = torch.silu(torch.add(_475, CONSTANTS.c474))\n",
      "  _476 = torch.matmul(input225, CONSTANTS.c475)\n",
      "  _477 = torch.mul(torch.add(_476, CONSTANTS.c476), CONSTANTS.c20)\n",
      "  x144 = torch.add(x143, _477)\n",
      "  input226 = torch.to(x144, 6)\n",
      "  _478 = torch.layer_norm(input226, [256], CONSTANTS.c477, CONSTANTS.c478)\n",
      "  query12 = torch.to(_478, 5)\n",
      "  _479 = torch.size(query12, 0)\n",
      "  _480 = torch.add(torch.matmul(query12, CONSTANTS.c479), CONSTANTS.c480)\n",
      "  _481 = torch.slice(_480, -1, 512, 768)\n",
      "  _482 = torch.slice(_480, -1, 256, 512)\n",
      "  _483 = torch.slice(_480, -1, 0, 256)\n",
      "  _484 = [_479, -1, 4, 64]\n",
      "  q38 = torch.view(_483, _484)\n",
      "  k25 = torch.view(_482, _484)\n",
      "  v12 = torch.view(_481, _484)\n",
      "  q39 = torch.transpose(q38, 1, 2)\n",
      "  k26 = torch.transpose(k25, 1, 2)\n",
      "  value12 = torch.transpose(v12, 1, 2)\n",
      "  q40 = torch.transpose(q39, 1, 2)\n",
      "  p25 = torch.view(torch.matmul(_22, CONSTANTS.c481), _24)\n",
      "  p26 = torch.transpose(p25, 1, 2)\n",
      "  q_with_bias_u12 = torch.transpose(torch.add(q40, CONSTANTS.c482), 1, 2)\n",
      "  q_with_bias_v12 = torch.transpose(torch.add(q40, CONSTANTS.c483), 1, 2)\n",
      "  _485 = torch.transpose(k26, -2, -1)\n",
      "  matrix_ac12 = torch.matmul(torch.to(q_with_bias_u12, 5), _485)\n",
      "  _486 = torch.transpose(p26, -2, -1)\n",
      "  x145 = torch.matmul(torch.to(q_with_bias_v12, 5), _486)\n",
      "  _487 = torch.size(x145, 0)\n",
      "  _488 = torch.size(x145, 1)\n",
      "  _489 = torch.size(x145, 2)\n",
      "  _490 = torch.size(x145, 3)\n",
      "  x146 = torch.constant_pad_nd(x145, [1, 0], 0.)\n",
      "  x147 = torch.view(x146, [_487, _488, -1, _489])\n",
      "  _491 = torch.slice(x147, 0, 0, 9223372036854775807)\n",
      "  _492 = torch.slice(_491, 1, 0, 9223372036854775807)\n",
      "  _493 = torch.slice(_492, 2, 1, 9223372036854775807)\n",
      "  matrix_bd25 = torch.view(_493, [_487, _488, _489, _490])\n",
      "  _494 = torch.size(matrix_ac12, -1)\n",
      "  _495 = torch.slice(matrix_bd25, 0, 0, 9223372036854775807)\n",
      "  _496 = torch.slice(_495, 1, 0, 9223372036854775807)\n",
      "  _497 = torch.slice(_496, 2, 0, 9223372036854775807)\n",
      "  matrix_bd26 = torch.slice(_497, 3, 0, _494)\n",
      "  scores25 = torch.div(torch.add(matrix_ac12, matrix_bd26), CONSTANTS.c28)\n",
      "  _498 = torch.size(value12, 0)\n",
      "  scores26 = torch.masked_fill(scores25, mask0, -10000.)\n",
      "  input227 = torch.masked_fill(torch.softmax(scores26, -1, 6), mask0, 0.)\n",
      "  x148 = torch.matmul(torch.to(input227, 5), value12)\n",
      "  input228 = torch.reshape(torch.transpose(x148, 1, 2), [_498, -1, 256])\n",
      "  _499 = torch.matmul(input228, CONSTANTS.c484)\n",
      "  x149 = torch.add(x144, torch.add(_499, CONSTANTS.c485))\n",
      "  input229 = torch.to(x149, 6)\n",
      "  _500 = torch.layer_norm(input229, [256], CONSTANTS.c486, CONSTANTS.c487)\n",
      "  x150 = torch.to(_500, 5)\n",
      "  input230 = torch.transpose(x150, 1, 2)\n",
      "  _501 = torch.conv1d(input230, CONSTANTS.c488, CONSTANTS.c489)\n",
      "  x151 = torch.glu(_501, 1)\n",
      "  input231 = torch.masked_fill(torch.to(x151, 6), _43, 0.)\n",
      "  _502 = torch.conv1d(torch.to(input231, 5), CONSTANTS.c490, CONSTANTS.c491, [1], [15], [1], 256)\n",
      "  input232 = torch.to(_502, 6)\n",
      "  _503 = torch.batch_norm(input232, CONSTANTS.c492, CONSTANTS.c493, CONSTANTS.c494, CONSTANTS.c495, False, 0.10000000000000001, 1.0000000000000001e-05, True)\n",
      "  input233 = torch.to(_503, 5)\n",
      "  input234 = torch.silu(input233)\n",
      "  _504 = torch.conv1d(input234, CONSTANTS.c496, CONSTANTS.c497)\n",
      "  input235 = torch.transpose(_504, 1, 2)\n",
      "  x152 = torch.add(x149, input235)\n",
      "  input236 = torch.to(x152, 6)\n",
      "  _505 = torch.layer_norm(input236, [256], CONSTANTS.c498, CONSTANTS.c499)\n",
      "  input237 = torch.to(_505, 5)\n",
      "  _506 = torch.matmul(input237, CONSTANTS.c500)\n",
      "  input238 = torch.silu(torch.add(_506, CONSTANTS.c501))\n",
      "  _507 = torch.matmul(input238, CONSTANTS.c502)\n",
      "  _508 = torch.mul(torch.add(_507, CONSTANTS.c503), CONSTANTS.c20)\n",
      "  x153 = torch.add(x152, _508)\n",
      "  input239 = torch.to(x153, 6)\n",
      "  _509 = torch.layer_norm(input239, [256], CONSTANTS.c504, CONSTANTS.c505)\n",
      "  x154 = torch.to(_509, 5)\n",
      "  input240 = torch.to(x154, 6)\n",
      "  _510 = torch.layer_norm(input240, [256], CONSTANTS.c506, CONSTANTS.c507)\n",
      "  input241 = torch.to(_510, 5)\n",
      "  _511 = torch.matmul(input241, CONSTANTS.c508)\n",
      "  input242 = torch.silu(torch.add(_511, CONSTANTS.c509))\n",
      "  _512 = torch.matmul(input242, CONSTANTS.c510)\n",
      "  _513 = torch.mul(torch.add(_512, CONSTANTS.c511), CONSTANTS.c20)\n",
      "  x155 = torch.add(x154, _513)\n",
      "  input243 = torch.to(x155, 6)\n",
      "  _514 = torch.layer_norm(input243, [256], CONSTANTS.c512, CONSTANTS.c513)\n",
      "  query13 = torch.to(_514, 5)\n",
      "  _515 = torch.size(query13, 0)\n",
      "  _516 = torch.add(torch.matmul(query13, CONSTANTS.c514), CONSTANTS.c515)\n",
      "  _517 = torch.slice(_516, -1, 512, 768)\n",
      "  _518 = torch.slice(_516, -1, 256, 512)\n",
      "  _519 = torch.slice(_516, -1, 0, 256)\n",
      "  _520 = [_515, -1, 4, 64]\n",
      "  q41 = torch.view(_519, _520)\n",
      "  k27 = torch.view(_518, _520)\n",
      "  v13 = torch.view(_517, _520)\n",
      "  q42 = torch.transpose(q41, 1, 2)\n",
      "  k28 = torch.transpose(k27, 1, 2)\n",
      "  value13 = torch.transpose(v13, 1, 2)\n",
      "  q43 = torch.transpose(q42, 1, 2)\n",
      "  p27 = torch.view(torch.matmul(_22, CONSTANTS.c516), _24)\n",
      "  p28 = torch.transpose(p27, 1, 2)\n",
      "  q_with_bias_u13 = torch.transpose(torch.add(q43, CONSTANTS.c517), 1, 2)\n",
      "  q_with_bias_v13 = torch.transpose(torch.add(q43, CONSTANTS.c518), 1, 2)\n",
      "  _521 = torch.transpose(k28, -2, -1)\n",
      "  matrix_ac13 = torch.matmul(torch.to(q_with_bias_u13, 5), _521)\n",
      "  _522 = torch.transpose(p28, -2, -1)\n",
      "  x156 = torch.matmul(torch.to(q_with_bias_v13, 5), _522)\n",
      "  _523 = torch.size(x156, 0)\n",
      "  _524 = torch.size(x156, 1)\n",
      "  _525 = torch.size(x156, 2)\n",
      "  _526 = torch.size(x156, 3)\n",
      "  x157 = torch.constant_pad_nd(x156, [1, 0], 0.)\n",
      "  x158 = torch.view(x157, [_523, _524, -1, _525])\n",
      "  _527 = torch.slice(x158, 0, 0, 9223372036854775807)\n",
      "  _528 = torch.slice(_527, 1, 0, 9223372036854775807)\n",
      "  _529 = torch.slice(_528, 2, 1, 9223372036854775807)\n",
      "  matrix_bd27 = torch.view(_529, [_523, _524, _525, _526])\n",
      "  _530 = torch.size(matrix_ac13, -1)\n",
      "  _531 = torch.slice(matrix_bd27, 0, 0, 9223372036854775807)\n",
      "  _532 = torch.slice(_531, 1, 0, 9223372036854775807)\n",
      "  _533 = torch.slice(_532, 2, 0, 9223372036854775807)\n",
      "  matrix_bd28 = torch.slice(_533, 3, 0, _530)\n",
      "  scores27 = torch.div(torch.add(matrix_ac13, matrix_bd28), CONSTANTS.c28)\n",
      "  _534 = torch.size(value13, 0)\n",
      "  scores28 = torch.masked_fill(scores27, mask0, -10000.)\n",
      "  input244 = torch.masked_fill(torch.softmax(scores28, -1, 6), mask0, 0.)\n",
      "  x159 = torch.matmul(torch.to(input244, 5), value13)\n",
      "  input245 = torch.reshape(torch.transpose(x159, 1, 2), [_534, -1, 256])\n",
      "  _535 = torch.matmul(input245, CONSTANTS.c519)\n",
      "  x160 = torch.add(x155, torch.add(_535, CONSTANTS.c520))\n",
      "  input246 = torch.to(x160, 6)\n",
      "  _536 = torch.layer_norm(input246, [256], CONSTANTS.c521, CONSTANTS.c522)\n",
      "  x161 = torch.to(_536, 5)\n",
      "  input247 = torch.transpose(x161, 1, 2)\n",
      "  _537 = torch.conv1d(input247, CONSTANTS.c523, CONSTANTS.c524)\n",
      "  x162 = torch.glu(_537, 1)\n",
      "  input248 = torch.masked_fill(torch.to(x162, 6), _43, 0.)\n",
      "  _538 = torch.conv1d(torch.to(input248, 5), CONSTANTS.c525, CONSTANTS.c526, [1], [15], [1], 256)\n",
      "  input249 = torch.to(_538, 6)\n",
      "  _539 = torch.batch_norm(input249, CONSTANTS.c527, CONSTANTS.c528, CONSTANTS.c529, CONSTANTS.c530, False, 0.10000000000000001, 1.0000000000000001e-05, True)\n",
      "  input250 = torch.to(_539, 5)\n",
      "  input251 = torch.silu(input250)\n",
      "  _540 = torch.conv1d(input251, CONSTANTS.c531, CONSTANTS.c532)\n",
      "  input252 = torch.transpose(_540, 1, 2)\n",
      "  x163 = torch.add(x160, input252)\n",
      "  input253 = torch.to(x163, 6)\n",
      "  _541 = torch.layer_norm(input253, [256], CONSTANTS.c533, CONSTANTS.c534)\n",
      "  input254 = torch.to(_541, 5)\n",
      "  _542 = torch.matmul(input254, CONSTANTS.c535)\n",
      "  input255 = torch.silu(torch.add(_542, CONSTANTS.c536))\n",
      "  _543 = torch.matmul(input255, CONSTANTS.c537)\n",
      "  _544 = torch.mul(torch.add(_543, CONSTANTS.c538), CONSTANTS.c20)\n",
      "  x164 = torch.add(x163, _544)\n",
      "  input256 = torch.to(x164, 6)\n",
      "  _545 = torch.layer_norm(input256, [256], CONSTANTS.c539, CONSTANTS.c540)\n",
      "  x165 = torch.to(_545, 5)\n",
      "  input257 = torch.to(x165, 6)\n",
      "  _546 = torch.layer_norm(input257, [256], CONSTANTS.c541, CONSTANTS.c542)\n",
      "  input258 = torch.to(_546, 5)\n",
      "  _547 = torch.matmul(input258, CONSTANTS.c543)\n",
      "  input259 = torch.silu(torch.add(_547, CONSTANTS.c544))\n",
      "  _548 = torch.matmul(input259, CONSTANTS.c545)\n",
      "  _549 = torch.mul(torch.add(_548, CONSTANTS.c546), CONSTANTS.c20)\n",
      "  x166 = torch.add(x165, _549)\n",
      "  input260 = torch.to(x166, 6)\n",
      "  _550 = torch.layer_norm(input260, [256], CONSTANTS.c547, CONSTANTS.c548)\n",
      "  query14 = torch.to(_550, 5)\n",
      "  _551 = torch.size(query14, 0)\n",
      "  _552 = torch.add(torch.matmul(query14, CONSTANTS.c549), CONSTANTS.c550)\n",
      "  _553 = torch.slice(_552, -1, 512, 768)\n",
      "  _554 = torch.slice(_552, -1, 256, 512)\n",
      "  _555 = torch.slice(_552, -1, 0, 256)\n",
      "  _556 = [_551, -1, 4, 64]\n",
      "  q44 = torch.view(_555, _556)\n",
      "  k29 = torch.view(_554, _556)\n",
      "  v14 = torch.view(_553, _556)\n",
      "  q45 = torch.transpose(q44, 1, 2)\n",
      "  k30 = torch.transpose(k29, 1, 2)\n",
      "  value14 = torch.transpose(v14, 1, 2)\n",
      "  q46 = torch.transpose(q45, 1, 2)\n",
      "  p29 = torch.view(torch.matmul(_22, CONSTANTS.c551), _24)\n",
      "  p30 = torch.transpose(p29, 1, 2)\n",
      "  q_with_bias_u14 = torch.transpose(torch.add(q46, CONSTANTS.c552), 1, 2)\n",
      "  q_with_bias_v14 = torch.transpose(torch.add(q46, CONSTANTS.c553), 1, 2)\n",
      "  _557 = torch.transpose(k30, -2, -1)\n",
      "  matrix_ac14 = torch.matmul(torch.to(q_with_bias_u14, 5), _557)\n",
      "  _558 = torch.transpose(p30, -2, -1)\n",
      "  x167 = torch.matmul(torch.to(q_with_bias_v14, 5), _558)\n",
      "  _559 = torch.size(x167, 0)\n",
      "  _560 = torch.size(x167, 1)\n",
      "  _561 = torch.size(x167, 2)\n",
      "  _562 = torch.size(x167, 3)\n",
      "  x168 = torch.constant_pad_nd(x167, [1, 0], 0.)\n",
      "  x169 = torch.view(x168, [_559, _560, -1, _561])\n",
      "  _563 = torch.slice(x169, 0, 0, 9223372036854775807)\n",
      "  _564 = torch.slice(_563, 1, 0, 9223372036854775807)\n",
      "  _565 = torch.slice(_564, 2, 1, 9223372036854775807)\n",
      "  matrix_bd29 = torch.view(_565, [_559, _560, _561, _562])\n",
      "  _566 = torch.size(matrix_ac14, -1)\n",
      "  _567 = torch.slice(matrix_bd29, 0, 0, 9223372036854775807)\n",
      "  _568 = torch.slice(_567, 1, 0, 9223372036854775807)\n",
      "  _569 = torch.slice(_568, 2, 0, 9223372036854775807)\n",
      "  matrix_bd30 = torch.slice(_569, 3, 0, _566)\n",
      "  scores29 = torch.div(torch.add(matrix_ac14, matrix_bd30), CONSTANTS.c28)\n",
      "  _570 = torch.size(value14, 0)\n",
      "  scores30 = torch.masked_fill(scores29, mask0, -10000.)\n",
      "  input261 = torch.masked_fill(torch.softmax(scores30, -1, 6), mask0, 0.)\n",
      "  x170 = torch.matmul(torch.to(input261, 5), value14)\n",
      "  input262 = torch.reshape(torch.transpose(x170, 1, 2), [_570, -1, 256])\n",
      "  _571 = torch.matmul(input262, CONSTANTS.c554)\n",
      "  x171 = torch.add(x166, torch.add(_571, CONSTANTS.c555))\n",
      "  input263 = torch.to(x171, 6)\n",
      "  _572 = torch.layer_norm(input263, [256], CONSTANTS.c556, CONSTANTS.c557)\n",
      "  x172 = torch.to(_572, 5)\n",
      "  input264 = torch.transpose(x172, 1, 2)\n",
      "  _573 = torch.conv1d(input264, CONSTANTS.c558, CONSTANTS.c559)\n",
      "  x173 = torch.glu(_573, 1)\n",
      "  input265 = torch.masked_fill(torch.to(x173, 6), _43, 0.)\n",
      "  _574 = torch.conv1d(torch.to(input265, 5), CONSTANTS.c560, CONSTANTS.c561, [1], [15], [1], 256)\n",
      "  input266 = torch.to(_574, 6)\n",
      "  _575 = torch.batch_norm(input266, CONSTANTS.c562, CONSTANTS.c563, CONSTANTS.c564, CONSTANTS.c565, False, 0.10000000000000001, 1.0000000000000001e-05, True)\n",
      "  input267 = torch.to(_575, 5)\n",
      "  input268 = torch.silu(input267)\n",
      "  _576 = torch.conv1d(input268, CONSTANTS.c566, CONSTANTS.c567)\n",
      "  input269 = torch.transpose(_576, 1, 2)\n",
      "  x174 = torch.add(x171, input269)\n",
      "  input270 = torch.to(x174, 6)\n",
      "  _577 = torch.layer_norm(input270, [256], CONSTANTS.c568, CONSTANTS.c569)\n",
      "  input271 = torch.to(_577, 5)\n",
      "  _578 = torch.matmul(input271, CONSTANTS.c570)\n",
      "  input272 = torch.silu(torch.add(_578, CONSTANTS.c571))\n",
      "  _579 = torch.matmul(input272, CONSTANTS.c572)\n",
      "  _580 = torch.mul(torch.add(_579, CONSTANTS.c573), CONSTANTS.c20)\n",
      "  x175 = torch.add(x174, _580)\n",
      "  input273 = torch.to(x175, 6)\n",
      "  _581 = torch.layer_norm(input273, [256], CONSTANTS.c574, CONSTANTS.c575)\n",
      "  x176 = torch.to(_581, 5)\n",
      "  input274 = torch.to(x176, 6)\n",
      "  _582 = torch.layer_norm(input274, [256], CONSTANTS.c576, CONSTANTS.c577)\n",
      "  input275 = torch.to(_582, 5)\n",
      "  _583 = torch.matmul(input275, CONSTANTS.c578)\n",
      "  input276 = torch.silu(torch.add(_583, CONSTANTS.c579))\n",
      "  _584 = torch.matmul(input276, CONSTANTS.c580)\n",
      "  _585 = torch.mul(torch.add(_584, CONSTANTS.c581), CONSTANTS.c20)\n",
      "  x177 = torch.add(x176, _585)\n",
      "  input277 = torch.to(x177, 6)\n",
      "  _586 = torch.layer_norm(input277, [256], CONSTANTS.c582, CONSTANTS.c583)\n",
      "  query15 = torch.to(_586, 5)\n",
      "  _587 = torch.size(query15, 0)\n",
      "  _588 = torch.add(torch.matmul(query15, CONSTANTS.c584), CONSTANTS.c585)\n",
      "  _589 = torch.slice(_588, -1, 512, 768)\n",
      "  _590 = torch.slice(_588, -1, 256, 512)\n",
      "  _591 = torch.slice(_588, -1, 0, 256)\n",
      "  _592 = [_587, -1, 4, 64]\n",
      "  q47 = torch.view(_591, _592)\n",
      "  k31 = torch.view(_590, _592)\n",
      "  v15 = torch.view(_589, _592)\n",
      "  q48 = torch.transpose(q47, 1, 2)\n",
      "  k32 = torch.transpose(k31, 1, 2)\n",
      "  value15 = torch.transpose(v15, 1, 2)\n",
      "  q49 = torch.transpose(q48, 1, 2)\n",
      "  p31 = torch.view(torch.matmul(_22, CONSTANTS.c586), _24)\n",
      "  p32 = torch.transpose(p31, 1, 2)\n",
      "  q_with_bias_u15 = torch.transpose(torch.add(q49, CONSTANTS.c587), 1, 2)\n",
      "  q_with_bias_v15 = torch.transpose(torch.add(q49, CONSTANTS.c588), 1, 2)\n",
      "  _593 = torch.transpose(k32, -2, -1)\n",
      "  matrix_ac15 = torch.matmul(torch.to(q_with_bias_u15, 5), _593)\n",
      "  _594 = torch.transpose(p32, -2, -1)\n",
      "  x178 = torch.matmul(torch.to(q_with_bias_v15, 5), _594)\n",
      "  _595 = torch.size(x178, 0)\n",
      "  _596 = torch.size(x178, 1)\n",
      "  _597 = torch.size(x178, 2)\n",
      "  _598 = torch.size(x178, 3)\n",
      "  x179 = torch.constant_pad_nd(x178, [1, 0], 0.)\n",
      "  x180 = torch.view(x179, [_595, _596, -1, _597])\n",
      "  _599 = torch.slice(x180, 0, 0, 9223372036854775807)\n",
      "  _600 = torch.slice(_599, 1, 0, 9223372036854775807)\n",
      "  _601 = torch.slice(_600, 2, 1, 9223372036854775807)\n",
      "  matrix_bd31 = torch.view(_601, [_595, _596, _597, _598])\n",
      "  _602 = torch.size(matrix_ac15, -1)\n",
      "  _603 = torch.slice(matrix_bd31, 0, 0, 9223372036854775807)\n",
      "  _604 = torch.slice(_603, 1, 0, 9223372036854775807)\n",
      "  _605 = torch.slice(_604, 2, 0, 9223372036854775807)\n",
      "  matrix_bd32 = torch.slice(_605, 3, 0, _602)\n",
      "  scores31 = torch.div(torch.add(matrix_ac15, matrix_bd32), CONSTANTS.c28)\n",
      "  _606 = torch.size(value15, 0)\n",
      "  scores32 = torch.masked_fill(scores31, mask0, -10000.)\n",
      "  input278 = torch.masked_fill(torch.softmax(scores32, -1, 6), mask0, 0.)\n",
      "  x181 = torch.matmul(torch.to(input278, 5), value15)\n",
      "  input279 = torch.reshape(torch.transpose(x181, 1, 2), [_606, -1, 256])\n",
      "  _607 = torch.matmul(input279, CONSTANTS.c589)\n",
      "  x182 = torch.add(x177, torch.add(_607, CONSTANTS.c590))\n",
      "  input280 = torch.to(x182, 6)\n",
      "  _608 = torch.layer_norm(input280, [256], CONSTANTS.c591, CONSTANTS.c592)\n",
      "  x183 = torch.to(_608, 5)\n",
      "  input281 = torch.transpose(x183, 1, 2)\n",
      "  _609 = torch.conv1d(input281, CONSTANTS.c593, CONSTANTS.c594)\n",
      "  x184 = torch.glu(_609, 1)\n",
      "  input282 = torch.masked_fill(torch.to(x184, 6), _43, 0.)\n",
      "  _610 = torch.conv1d(torch.to(input282, 5), CONSTANTS.c595, CONSTANTS.c596, [1], [15], [1], 256)\n",
      "  input283 = torch.to(_610, 6)\n",
      "  _611 = torch.batch_norm(input283, CONSTANTS.c597, CONSTANTS.c598, CONSTANTS.c599, CONSTANTS.c600, False, 0.10000000000000001, 1.0000000000000001e-05, True)\n",
      "  input284 = torch.to(_611, 5)\n",
      "  input285 = torch.silu(input284)\n",
      "  _612 = torch.conv1d(input285, CONSTANTS.c601, CONSTANTS.c602)\n",
      "  input286 = torch.transpose(_612, 1, 2)\n",
      "  x185 = torch.add(x182, input286)\n",
      "  input287 = torch.to(x185, 6)\n",
      "  _613 = torch.layer_norm(input287, [256], CONSTANTS.c603, CONSTANTS.c604)\n",
      "  input288 = torch.to(_613, 5)\n",
      "  _614 = torch.matmul(input288, CONSTANTS.c605)\n",
      "  input289 = torch.silu(torch.add(_614, CONSTANTS.c606))\n",
      "  _615 = torch.matmul(input289, CONSTANTS.c607)\n",
      "  _616 = torch.mul(torch.add(_615, CONSTANTS.c608), CONSTANTS.c20)\n",
      "  x186 = torch.add(x185, _616)\n",
      "  input290 = torch.to(x186, 6)\n",
      "  _617 = torch.layer_norm(input290, [256], CONSTANTS.c609, CONSTANTS.c610)\n",
      "  x187 = torch.to(_617, 5)\n",
      "  input291 = torch.to(x187, 6)\n",
      "  _618 = torch.layer_norm(input291, [256], CONSTANTS.c611, CONSTANTS.c612)\n",
      "  input292 = torch.to(_618, 5)\n",
      "  _619 = torch.matmul(input292, CONSTANTS.c613)\n",
      "  input293 = torch.silu(torch.add(_619, CONSTANTS.c614))\n",
      "  _620 = torch.matmul(input293, CONSTANTS.c615)\n",
      "  _621 = torch.mul(torch.add(_620, CONSTANTS.c616), CONSTANTS.c20)\n",
      "  x188 = torch.add(x187, _621)\n",
      "  input294 = torch.to(x188, 6)\n",
      "  _622 = torch.layer_norm(input294, [256], CONSTANTS.c617, CONSTANTS.c618)\n",
      "  query16 = torch.to(_622, 5)\n",
      "  _623 = torch.size(query16, 0)\n",
      "  _624 = torch.add(torch.matmul(query16, CONSTANTS.c619), CONSTANTS.c620)\n",
      "  _625 = torch.slice(_624, -1, 512, 768)\n",
      "  _626 = torch.slice(_624, -1, 256, 512)\n",
      "  _627 = torch.slice(_624, -1, 0, 256)\n",
      "  _628 = [_623, -1, 4, 64]\n",
      "  q50 = torch.view(_627, _628)\n",
      "  k33 = torch.view(_626, _628)\n",
      "  v16 = torch.view(_625, _628)\n",
      "  q51 = torch.transpose(q50, 1, 2)\n",
      "  k34 = torch.transpose(k33, 1, 2)\n",
      "  value16 = torch.transpose(v16, 1, 2)\n",
      "  q52 = torch.transpose(q51, 1, 2)\n",
      "  p33 = torch.view(torch.matmul(_22, CONSTANTS.c621), _24)\n",
      "  p34 = torch.transpose(p33, 1, 2)\n",
      "  q_with_bias_u16 = torch.transpose(torch.add(q52, CONSTANTS.c622), 1, 2)\n",
      "  q_with_bias_v16 = torch.transpose(torch.add(q52, CONSTANTS.c623), 1, 2)\n",
      "  _629 = torch.transpose(k34, -2, -1)\n",
      "  matrix_ac16 = torch.matmul(torch.to(q_with_bias_u16, 5), _629)\n",
      "  _630 = torch.transpose(p34, -2, -1)\n",
      "  x189 = torch.matmul(torch.to(q_with_bias_v16, 5), _630)\n",
      "  _631 = torch.size(x189, 0)\n",
      "  _632 = torch.size(x189, 1)\n",
      "  _633 = torch.size(x189, 2)\n",
      "  _634 = torch.size(x189, 3)\n",
      "  x190 = torch.constant_pad_nd(x189, [1, 0], 0.)\n",
      "  x191 = torch.view(x190, [_631, _632, -1, _633])\n",
      "  _635 = torch.slice(x191, 0, 0, 9223372036854775807)\n",
      "  _636 = torch.slice(_635, 1, 0, 9223372036854775807)\n",
      "  _637 = torch.slice(_636, 2, 1, 9223372036854775807)\n",
      "  matrix_bd33 = torch.view(_637, [_631, _632, _633, _634])\n",
      "  _638 = torch.size(matrix_ac16, -1)\n",
      "  _639 = torch.slice(matrix_bd33, 0, 0, 9223372036854775807)\n",
      "  _640 = torch.slice(_639, 1, 0, 9223372036854775807)\n",
      "  _641 = torch.slice(_640, 2, 0, 9223372036854775807)\n",
      "  matrix_bd34 = torch.slice(_641, 3, 0, _638)\n",
      "  scores33 = torch.div(torch.add(matrix_ac16, matrix_bd34), CONSTANTS.c28)\n",
      "  _642 = torch.size(value16, 0)\n",
      "  scores34 = torch.masked_fill(scores33, mask0, -10000.)\n",
      "  input295 = torch.masked_fill(torch.softmax(scores34, -1, 6), mask0, 0.)\n",
      "  x192 = torch.matmul(torch.to(input295, 5), value16)\n",
      "  input296 = torch.reshape(torch.transpose(x192, 1, 2), [_642, -1, 256])\n",
      "  _643 = torch.matmul(input296, CONSTANTS.c624)\n",
      "  x193 = torch.add(x188, torch.add(_643, CONSTANTS.c625))\n",
      "  input297 = torch.to(x193, 6)\n",
      "  _644 = torch.layer_norm(input297, [256], CONSTANTS.c626, CONSTANTS.c627)\n",
      "  x194 = torch.to(_644, 5)\n",
      "  input298 = torch.transpose(x194, 1, 2)\n",
      "  _645 = torch.conv1d(input298, CONSTANTS.c628, CONSTANTS.c629)\n",
      "  x195 = torch.glu(_645, 1)\n",
      "  input299 = torch.masked_fill(torch.to(x195, 6), _43, 0.)\n",
      "  _646 = torch.conv1d(torch.to(input299, 5), CONSTANTS.c630, CONSTANTS.c631, [1], [15], [1], 256)\n",
      "  input300 = torch.to(_646, 6)\n",
      "  _647 = torch.batch_norm(input300, CONSTANTS.c632, CONSTANTS.c633, CONSTANTS.c634, CONSTANTS.c635, False, 0.10000000000000001, 1.0000000000000001e-05, True)\n",
      "  input301 = torch.to(_647, 5)\n",
      "  input302 = torch.silu(input301)\n",
      "  _648 = torch.conv1d(input302, CONSTANTS.c636, CONSTANTS.c637)\n",
      "  input303 = torch.transpose(_648, 1, 2)\n",
      "  x196 = torch.add(x193, input303)\n",
      "  input304 = torch.to(x196, 6)\n",
      "  _649 = torch.layer_norm(input304, [256], CONSTANTS.c638, CONSTANTS.c639)\n",
      "  input305 = torch.to(_649, 5)\n",
      "  _650 = torch.matmul(input305, CONSTANTS.c640)\n",
      "  input306 = torch.silu(torch.add(_650, CONSTANTS.c641))\n",
      "  _651 = torch.matmul(input306, CONSTANTS.c642)\n",
      "  _652 = torch.mul(torch.add(_651, CONSTANTS.c643), CONSTANTS.c20)\n",
      "  x197 = torch.add(x196, _652)\n",
      "  input307 = torch.to(x197, 6)\n",
      "  _653 = torch.layer_norm(input307, [256], CONSTANTS.c644, CONSTANTS.c645)\n",
      "  audio_signal = torch.to(_653, 5)\n",
      "  input308 = torch.transpose(audio_signal, 1, 2)\n",
      "  _654 = torch.conv1d(input308, CONSTANTS.c646, CONSTANTS.c647)\n",
      "  input309 = torch.transpose(_654, 1, 2)\n",
      "  return torch.log_softmax(input309, -1, 6)\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb5896f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecursiveScriptModule(original_name=EncDecCTCModelBPE)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48fcb145",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav, _ =sf.read('/home/harveen/evaluations/taarini_without_numbers/244-F-29_033.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "65198fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ta, sr = torchaudio.load('/home/harveen/evaluations/taarini_without_numbers/244-F-29_033.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "354fffeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.tensor(wav)\n",
    "input_length = torch.tensor(len(input_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8643128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(119040)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b5cc1233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(len(test_ta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "855c51c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript, serialized code (most recent call last):\n  File \"code/__torch__/nemo/collections/asr/models/ctc_bpe_models/___torch_mangle_643.py\", line 7, in forward\n    input: Tensor,\n    length: Tensor) -> Tensor:\n    x = torch.transpose(input, 1, 2)\n        ~~~~~~~~~~~~~~~ <--- HERE\n    _0 = torch.add(torch.to(length, 6), CONSTANTS.c0)\n    lengths = torch.add(torch.div(_0, CONSTANTS.c1), CONSTANTS.c2)\n\nTraceback of TorchScript, original code (most recent call last):\n/opt/conda/envs/nemo/lib/python3.8/site-packages/nemo/collections/asr/modules/conformer_encoder.py(248): forward_for_export\n/opt/conda/envs/nemo/lib/python3.8/site-packages/nemo/collections/asr/models/asr_model.py(120): forward_for_export\n/opt/conda/envs/nemo/lib/python3.8/site-packages/torch/nn/modules/module.py(1098): _slow_forward\n/opt/conda/envs/nemo/lib/python3.8/site-packages/torch/nn/modules/module.py(1110): _call_impl\n/opt/conda/envs/nemo/lib/python3.8/site-packages/torch/jit/_trace.py(958): trace_module\n/opt/conda/envs/nemo/lib/python3.8/site-packages/nemo/core/classes/exportable.py(120): export\n../../src/inference/export.py(116): nemo_export\n../../src/inference/export.py(141): <module>\nRuntimeError: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [37]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_ta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript, serialized code (most recent call last):\n  File \"code/__torch__/nemo/collections/asr/models/ctc_bpe_models/___torch_mangle_643.py\", line 7, in forward\n    input: Tensor,\n    length: Tensor) -> Tensor:\n    x = torch.transpose(input, 1, 2)\n        ~~~~~~~~~~~~~~~ <--- HERE\n    _0 = torch.add(torch.to(length, 6), CONSTANTS.c0)\n    lengths = torch.add(torch.div(_0, CONSTANTS.c1), CONSTANTS.c2)\n\nTraceback of TorchScript, original code (most recent call last):\n/opt/conda/envs/nemo/lib/python3.8/site-packages/nemo/collections/asr/modules/conformer_encoder.py(248): forward_for_export\n/opt/conda/envs/nemo/lib/python3.8/site-packages/nemo/collections/asr/models/asr_model.py(120): forward_for_export\n/opt/conda/envs/nemo/lib/python3.8/site-packages/torch/nn/modules/module.py(1098): _slow_forward\n/opt/conda/envs/nemo/lib/python3.8/site-packages/torch/nn/modules/module.py(1110): _call_impl\n/opt/conda/envs/nemo/lib/python3.8/site-packages/torch/jit/_trace.py(958): trace_module\n/opt/conda/envs/nemo/lib/python3.8/site-packages/nemo/core/classes/exportable.py(120): export\n../../src/inference/export.py(116): nemo_export\n../../src/inference/export.py(141): <module>\nRuntimeError: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n"
     ]
    }
   ],
   "source": [
    "model.forward(test_ta, torch.tensor(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227b56d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
